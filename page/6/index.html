<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('http://yoursite.com').hostname,
    root: '/',
    scheme: 'Gemini',
    version: '7.7.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta name="description" content="其实，我是一个搬运工！">
<meta property="og:type" content="website">
<meta property="og:title" content="Paper搬运菌">
<meta property="og:url" content="http://yoursite.com/page/6/index.html">
<meta property="og:site_name" content="Paper搬运菌">
<meta property="og:description" content="其实，我是一个搬运工！">
<meta property="og:locale" content="en_US">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://yoursite.com/page/6/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: true,
    isPost: false
  };
</script>

  <title>Paper搬运菌</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Paper搬运菌</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/15/PyTorch%E7%AC%94%E8%AE%B0/%E3%80%90Tutorials%E3%80%91TensorBoard-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="其实，我是一个搬运工！">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Paper搬运菌">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2019/09/15/PyTorch%E7%AC%94%E8%AE%B0/%E3%80%90Tutorials%E3%80%91TensorBoard-1/" class="post-title-link" itemprop="url">PyTorch笔记/【Tutorials】TensorBoard-1</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-09-15 00:00:00" itemprop="dateCreated datePublished" datetime="2019-09-15T00:00:00+08:00">2019-09-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-05-27 10:25:22" itemprop="dateModified" datetime="2020-05-27T10:25:22+08:00">2020-05-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/PyTorch%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index">
                    <span itemprop="name">PyTorch笔记</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <a id="more"></a>
<h1 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h1><p>要求tensorboard版本至少是1.14<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pip3 install tensorboard</span><br></pre></td></tr></table></figure></p>
<h1 id="tensorboard使用示例"><a href="#tensorboard使用示例" class="headerlink" title="tensorboard使用示例"></a>tensorboard使用示例</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(comment=<span class="string">'test_tensorboard'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    writer.add_scalar(<span class="string">'y=2x'</span>, x * <span class="number">2</span>, x)</span><br><span class="line">    writer.add_scalar(<span class="string">'y=pow(2, x)'</span>, <span class="number">2</span> ** x, x)</span><br><span class="line"></span><br><span class="line">    writer.add_scalars(<span class="string">'data/scalar_group'</span>, &#123;<span class="string">"xsinx"</span>: x * np.sin(x),</span><br><span class="line">                                             <span class="string">"xcosx"</span>: x * np.cos(x),</span><br><span class="line">                                             <span class="string">"arctanx"</span>: np.arctan(x)&#125;, x)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> to project path</span><br><span class="line">$ tensorboard --logdir=./runs</span><br></pre></td></tr></table></figure>
<h1 id="SummaryWriter使用详解"><a href="#SummaryWriter使用详解" class="headerlink" title="SummaryWriter使用详解"></a>SummaryWriter使用详解</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SummaryWriter</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">"""Writes entries directly to event files in the log_dir to be</span></span><br><span class="line"><span class="string">    consumed by TensorBoard.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    The `SummaryWriter` class provides a high-level API to create an event file</span></span><br><span class="line"><span class="string">    in a given directory and add summaries and events to it. The class updates the</span></span><br><span class="line"><span class="string">    file contents asynchronously. This allows a training program to call methods</span></span><br><span class="line"><span class="string">    to add data to the file directly from the training loop, without slowing down</span></span><br><span class="line"><span class="string">    training.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, log_dir=None, comment=<span class="string">''</span>, purge_step=None, max_queue=<span class="number">10</span>, flush_secs=<span class="number">120</span>, filename_suffix=<span class="string">''</span>)</span>:</span></span><br><span class="line">        <span class="string">"""Creates a `SummaryWriter` that will write out events and summaries</span></span><br><span class="line"><span class="string">        to the event file.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            log_dir (string): Save directory location. Default is</span></span><br><span class="line"><span class="string">              runs/**CURRENT_DATETIME_HOSTNAME**, which changes after each run.</span></span><br><span class="line"><span class="string">              Use hierarchical folder structure to compare</span></span><br><span class="line"><span class="string">              between runs easily. e.g. pass in 'runs/exp1', 'runs/exp2', etc.</span></span><br><span class="line"><span class="string">              for each new experiment to compare across them.</span></span><br><span class="line"><span class="string">            comment (string): Comment log_dir suffix appended to the default</span></span><br><span class="line"><span class="string">              ``log_dir``. If ``log_dir`` is assigned, this argument has no effect.</span></span><br><span class="line"><span class="string">            purge_step (int):</span></span><br><span class="line"><span class="string">              When logging crashes at step :math:`T+X` and restarts at step :math:`T`,</span></span><br><span class="line"><span class="string">              any events whose global_step larger or equal to :math:`T` will be</span></span><br><span class="line"><span class="string">              purged and hidden from TensorBoard.</span></span><br><span class="line"><span class="string">              Note that crashed and resumed experiments should have the same ``log_dir``.</span></span><br><span class="line"><span class="string">            max_queue (int): Size of the queue for pending events and</span></span><br><span class="line"><span class="string">              summaries before one of the 'add' calls forces a flush to disk.</span></span><br><span class="line"><span class="string">              Default is ten items.</span></span><br><span class="line"><span class="string">            flush_secs (int): How often, in seconds, to flush the</span></span><br><span class="line"><span class="string">              pending events and summaries to disk. Default is every two minutes.</span></span><br><span class="line"><span class="string">            filename_suffix (string): Suffix added to all event filenames in</span></span><br><span class="line"><span class="string">              the log_dir directory. More details on filename construction in</span></span><br><span class="line"><span class="string">              tensorboard.summary.writer.event_file_writer.EventFileWriter.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Examples::</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">            from torch.utils.tensorboard import SummaryWriter</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">            # create a summary writer with automatically generated folder name.</span></span><br><span class="line"><span class="string">            writer = SummaryWriter()</span></span><br><span class="line"><span class="string">            # folder location: runs/May04_22-14-54_s-MacBook-Pro.local/</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">            # create a summary writer using the specified folder name.</span></span><br><span class="line"><span class="string">            writer = SummaryWriter("my_experiment")</span></span><br><span class="line"><span class="string">            # folder location: my_experiment</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">            # create a summary writer with comment appended.</span></span><br><span class="line"><span class="string">            writer = SummaryWriter(comment="LR_0.1_BATCH_16")</span></span><br><span class="line"><span class="string">            # folder location: runs/May04_22-14-54_s-MacBook-Pro.localLR_0.1_BATCH_16/</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        torch._C._log_api_usage_once(<span class="string">"tensorboard.create.summarywriter"</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> log_dir:</span><br><span class="line">            <span class="keyword">import</span> socket</span><br><span class="line">            <span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line">            current_time = datetime.now().strftime(<span class="string">'%b%d_%H-%M-%S'</span>)</span><br><span class="line">            log_dir = os.path.join(</span><br><span class="line">                <span class="string">'runs'</span>, current_time + <span class="string">'_'</span> + socket.gethostname() + comment)</span><br><span class="line">        self.log_dir = log_dir</span><br><span class="line">        self.purge_step = purge_step</span><br><span class="line">        self.max_queue = max_queue</span><br><span class="line">        self.flush_secs = flush_secs</span><br><span class="line">        self.filename_suffix = filename_suffix</span><br><span class="line"></span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>
<p><strong>功能</strong>：提供创建event-file的高级接口</p>
<ul>
<li><strong>log_dir</strong>: event-file输出文件夹，如果不指定，则会在当前目录下创建runs文件夹，event-file将被保存到runs目录下的对应文件夹下；如果指定了log_dir，则comment不起作用；</li>
<li><strong>comment*</strong>: 不指定log_dir时，文件夹后缀</li>
<li><strong>filename_suffix</strong>: event-file 文件名后缀</li>
</ul>
<p><strong>注</strong>：通常不会使用默认的log_dir，因为开发中一般都要将代码和数据分离。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"><span class="comment"># flag = 0</span></span><br><span class="line">flag = <span class="number">1</span></span><br><span class="line"><span class="keyword">if</span> flag:</span><br><span class="line">    log_dir = <span class="string">"./train_log/test_log_dir"</span></span><br><span class="line">    <span class="comment"># writer = SummaryWriter(log_dir=log_dir, comment='_scalars', filename_suffix="12345678")</span></span><br><span class="line">    writer = SummaryWriter(comment=<span class="string">'_scalars'</span>, filename_suffix=<span class="string">"12345678"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">        writer.add_scalar(<span class="string">'y=pow_2_x'</span>, <span class="number">2</span> ** x, x)</span><br><span class="line"></span><br><span class="line">    writer.close()</span><br></pre></td></tr></table></figure>
<p><strong>指定log_dir时生成的文件目录</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── train_log</span><br><span class="line">│   └── test_log_dir</span><br><span class="line">│       └── events.out.tfevents.1583414749.ailab-server.13132.012345678</span><br></pre></td></tr></table></figure></p>
<p><strong>不指定log_dir时生成的文件目录</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── runs</span><br><span class="line">│   └── Mar05_08-26-58_ailab-server_scalars</span><br><span class="line">│       └── events.out.tfevents.1583414821.ailab-server.13260.012345678</span><br></pre></td></tr></table></figure></p>
<h2 id="成员方法：add-scalar"><a href="#成员方法：add-scalar" class="headerlink" title="成员方法：add_scalar"></a>成员方法：add_scalar</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SummaryWriter</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(...)</span>:</span></span><br><span class="line">        ...</span><br><span class="line">    </span><br><span class="line">    ... </span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_scalar</span><span class="params">(self, tag, scalar_value, global_step=None, walltime=None)</span>:</span></span><br><span class="line">        <span class="string">"""Add scalar data to summary.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            tag (string): Data identifier</span></span><br><span class="line"><span class="string">            scalar_value (float or string/blobname): Value to save</span></span><br><span class="line"><span class="string">            global_step (int): Global step value to record</span></span><br><span class="line"><span class="string">            walltime (float): Optional override default walltime (time.time())</span></span><br><span class="line"><span class="string">              with seconds after epoch of event</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Examples::</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">            from torch.utils.tensorboard import SummaryWriter</span></span><br><span class="line"><span class="string">            writer = SummaryWriter()</span></span><br><span class="line"><span class="string">            x = range(100)</span></span><br><span class="line"><span class="string">            for i in x:</span></span><br><span class="line"><span class="string">                writer.add_scalar('y=2x', i * 2, i)</span></span><br><span class="line"><span class="string">            writer.close()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Expected result:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        .. image:: _static/img/tensorboard/add_scalar.png</span></span><br><span class="line"><span class="string">           :scale: 50 %</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> self._check_caffe2_blob(scalar_value):</span><br><span class="line">            scalar_value = workspace.FetchBlob(scalar_value)</span><br><span class="line">        self._get_file_writer().add_summary(</span><br><span class="line">            scalar(tag, scalar_value), global_step, walltime)</span><br></pre></td></tr></table></figure>
<p><strong>功能</strong>：记录标量</p>
<ul>
<li><strong>tag</strong>: 图像标签名，图的唯一标识</li>
<li><strong>scalar_value</strong>: 要记录的标量</li>
<li><strong>global_step</strong>: x轴</li>
</ul>
<h2 id="成员方法：add-scalars"><a href="#成员方法：add-scalars" class="headerlink" title="成员方法：add_scalars"></a>成员方法：add_scalars</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SummaryWriter</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(...)</span>:</span></span><br><span class="line">        ...</span><br><span class="line">    </span><br><span class="line">    ... </span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_scalars</span><span class="params">(self, main_tag, tag_scalar_dict, global_step=None, walltime=None)</span>:</span></span><br><span class="line">        <span class="string">"""Adds many scalar data to summary.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Note that this function also keeps logged scalars in memory. In extreme case it explodes your RAM.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            main_tag (string): The parent name for the tags</span></span><br><span class="line"><span class="string">            tag_scalar_dict (dict): Key-value pair storing the tag and corresponding values</span></span><br><span class="line"><span class="string">            global_step (int): Global step value to record</span></span><br><span class="line"><span class="string">            walltime (float): Optional override default walltime (time.time())</span></span><br><span class="line"><span class="string">              seconds after epoch of event</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Examples::</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">            from torch.utils.tensorboard import SummaryWriter</span></span><br><span class="line"><span class="string">            writer = SummaryWriter()</span></span><br><span class="line"><span class="string">            r = 5</span></span><br><span class="line"><span class="string">            for i in range(100):</span></span><br><span class="line"><span class="string">                writer.add_scalars('run_14h', &#123;'xsinx':i*np.sin(i/r),</span></span><br><span class="line"><span class="string">                                                'xcosx':i*np.cos(i/r),</span></span><br><span class="line"><span class="string">                                                'tanx': np.tan(i/r)&#125;, i)</span></span><br><span class="line"><span class="string">            writer.close()</span></span><br><span class="line"><span class="string">            # This call adds three values to the same scalar plot with the tag</span></span><br><span class="line"><span class="string">            # 'run_14h' in TensorBoard's scalar section.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Expected result:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        .. image:: _static/img/tensorboard/add_scalars.png</span></span><br><span class="line"><span class="string">           :scale: 50 %</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        walltime = time.time() <span class="keyword">if</span> walltime <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> walltime</span><br><span class="line">        fw_logdir = self._get_file_writer().get_logdir()</span><br><span class="line">        <span class="keyword">for</span> tag, scalar_value <span class="keyword">in</span> tag_scalar_dict.items():</span><br><span class="line">            fw_tag = fw_logdir + <span class="string">"/"</span> + main_tag.replace(<span class="string">"/"</span>, <span class="string">"_"</span>) + <span class="string">"_"</span> + tag</span><br><span class="line">            <span class="keyword">if</span> fw_tag <span class="keyword">in</span> self.all_writers.keys():</span><br><span class="line">                fw = self.all_writers[fw_tag]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                fw = FileWriter(fw_tag, self.max_queue, self.flush_secs,</span><br><span class="line">                                self.filename_suffix)</span><br><span class="line">                self.all_writers[fw_tag] = fw</span><br><span class="line">            <span class="keyword">if</span> self._check_caffe2_blob(scalar_value):</span><br><span class="line">                scalar_value = workspace.FetchBlob(scalar_value)</span><br><span class="line">            fw.add_summary(scalar(main_tag, scalar_value),</span><br><span class="line">                           global_step, walltime)</span><br></pre></td></tr></table></figure>
<p><strong>功能</strong>：在同一个图中记录多个标量</p>
<ul>
<li><strong>main_tag</strong>: 该图的标签，等同于add_scalar中的tag</li>
<li><strong>tag_scalar_dict*</strong>: key是变量的tag，value是变量的值</li>
<li><strong>global_step</strong>: x轴</li>
</ul>
<p><strong>代码示例：</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"><span class="comment"># flag = 0</span></span><br><span class="line">flag = <span class="number">1</span></span><br><span class="line"><span class="keyword">if</span> flag:</span><br><span class="line"></span><br><span class="line">    max_epoch = <span class="number">100</span></span><br><span class="line"></span><br><span class="line">    writer = SummaryWriter(comment=<span class="string">'test_comment'</span>, filename_suffix=<span class="string">"test_suffix"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(max_epoch):</span><br><span class="line"></span><br><span class="line">        writer.add_scalar(<span class="string">'y=2x'</span>, x * <span class="number">2</span>, x)</span><br><span class="line">        writer.add_scalar(<span class="string">'y=pow_2_x'</span>, <span class="number">2</span> ** x, x)</span><br><span class="line"></span><br><span class="line">        writer.add_scalars(<span class="string">'data/scalar_group'</span>, &#123;<span class="string">"xsinx"</span>: x * np.sin(x),</span><br><span class="line">                                                 <span class="string">"xcosx"</span>: x * np.cos(x)&#125;, x)</span><br><span class="line"></span><br><span class="line">    writer.close()</span><br></pre></td></tr></table></figure></p>
<h2 id="成员方法：add-histogram"><a href="#成员方法：add-histogram" class="headerlink" title="成员方法：add_histogram"></a>成员方法：add_histogram</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SummaryWriter</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(...)</span>:</span></span><br><span class="line">        ...</span><br><span class="line">    </span><br><span class="line">    ... </span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_histogram</span><span class="params">(self, tag, values, global_step=None, bins=<span class="string">'tensorflow'</span>, walltime=None, max_bins=None)</span>:</span></span><br><span class="line">        <span class="string">"""Add histogram to summary.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            tag (string): Data identifier</span></span><br><span class="line"><span class="string">            values (torch.Tensor, numpy.array, or string/blobname): Values to build histogram</span></span><br><span class="line"><span class="string">            global_step (int): Global step value to record</span></span><br><span class="line"><span class="string">            bins (string): One of &#123;'tensorflow','auto', 'fd', ...&#125;. This determines how the bins are made. You can find</span></span><br><span class="line"><span class="string">              other options in: https://docs.scipy.org/doc/numpy/reference/generated/numpy.histogram.html</span></span><br><span class="line"><span class="string">            walltime (float): Optional override default walltime (time.time())</span></span><br><span class="line"><span class="string">              seconds after epoch of event</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Examples::</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">            from torch.utils.tensorboard import SummaryWriter</span></span><br><span class="line"><span class="string">            import numpy as np</span></span><br><span class="line"><span class="string">            writer = SummaryWriter()</span></span><br><span class="line"><span class="string">            for i in range(10):</span></span><br><span class="line"><span class="string">                x = np.random.random(1000)</span></span><br><span class="line"><span class="string">                writer.add_histogram('distribution centers', x + i, i)</span></span><br><span class="line"><span class="string">            writer.close()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Expected result:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        .. image:: _static/img/tensorboard/add_histogram.png</span></span><br><span class="line"><span class="string">           :scale: 50 %</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> self._check_caffe2_blob(values):</span><br><span class="line">            values = workspace.FetchBlob(values)</span><br><span class="line">        <span class="keyword">if</span> isinstance(bins, six.string_types) <span class="keyword">and</span> bins == <span class="string">'tensorflow'</span>:</span><br><span class="line">            bins = self.default_bins</span><br><span class="line">        self._get_file_writer().add_summary(</span><br><span class="line">            histogram(tag, values, bins, max_bins=max_bins), global_step, walltime)</span><br></pre></td></tr></table></figure>
<p><strong>功能</strong>：统计直方图与多分位数折线图，对模型分析模型参数分布以及梯度分布是很有用的。<br>关于多分位折线图，我的理解是：监控values的数值区间中多个位置的value的变化情况的折线图。</p>
<ul>
<li><strong>tag</strong>: 图像的标签名，图的唯一标识符</li>
<li><strong>values</strong>: 要统计的参数</li>
<li><strong>global_step</strong>: y轴</li>
<li><strong>bins</strong>: 取直方图的bins，通常取默认的“tensorflow”即可。（关于bins，我的理解就是将values的数值区间划分成一个个的bin(箱子)，然后统计落在每个bin的value的个数）</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"><span class="comment"># flag = 0</span></span><br><span class="line">flag = <span class="number">1</span></span><br><span class="line"><span class="keyword">if</span> flag:</span><br><span class="line"></span><br><span class="line">    writer = SummaryWriter(comment=<span class="string">'test_comment'</span>, filename_suffix=<span class="string">"test_suffix"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line"></span><br><span class="line">        np.random.seed(x)</span><br><span class="line"></span><br><span class="line">        data_union = np.arange(<span class="number">100</span>)</span><br><span class="line">        data_normal = np.random.normal(size=<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line">        writer.add_histogram(<span class="string">'distribution union'</span>, data_union, x)</span><br><span class="line">        writer.add_histogram(<span class="string">'distribution normal'</span>, data_normal, x)</span><br><span class="line"></span><br><span class="line">        plt.subplot(<span class="number">121</span>).hist(data_union, label=<span class="string">"union"</span>)</span><br><span class="line">        plt.subplot(<span class="number">122</span>).hist(data_normal, label=<span class="string">"normal"</span>)</span><br><span class="line">        plt.legend()</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">    writer.close()</span><br></pre></td></tr></table></figure>
<p>tensorboard(左)和plt(右)画的其中一个epoch的分布图如下：</p>
<div align=center>
  <img src="https://github.com/JuneXia/JuneXia.github.io/raw/hexo/source/images/ml/tensorboard_histograms.jpg" width = 50% height = 50% /><img src="https://github.com/JuneXia/JuneXia.github.io/raw/hexo/source/images/ml/tensorboard_histograms2.jpg" width = 50% height = 60% />
</div>

<p>可以看到plt画出的normal直方图和tensorboard画出的normal直方图基本类似，但是对于union直方图，正确的应该是plt所画出的图，tensorboard的是由于其内部做了一些显示上的优化。</p>
<p>再来看看tensorboard画出的distribution图（多分位数折线图）：</p>
<div align=center>
  <img src="https://github.com/JuneXia/JuneXia.github.io/raw/hexo/source/images/ml/tensorboard_distributions.jpg" width = 60% height = 60% />
</div>


<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] DeepShare.net &gt; PyTorch框架</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/15/PyTorch%E7%AC%94%E8%AE%B0/%E3%80%90Tutorials%E3%80%91TensorBoard-2%20%E7%9B%91%E6%8E%A7loss,acc,grad/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="其实，我是一个搬运工！">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Paper搬运菌">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2019/09/15/PyTorch%E7%AC%94%E8%AE%B0/%E3%80%90Tutorials%E3%80%91TensorBoard-2%20%E7%9B%91%E6%8E%A7loss,acc,grad/" class="post-title-link" itemprop="url">PyTorch笔记/【Tutorials】TensorBoard-2 监控loss,acc,grad</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-09-15 00:00:00" itemprop="dateCreated datePublished" datetime="2019-09-15T00:00:00+08:00">2019-09-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-03-07 14:21:03" itemprop="dateModified" datetime="2020-03-07T14:21:03+08:00">2020-03-07</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/PyTorch%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index">
                    <span itemprop="name">PyTorch笔记</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><strong>思路总结：</strong> \</p>
<ul>
<li>一般的，网络param的梯度在前面的epoch分布可能都会比较大，而越往后训练，这些梯度值一般会慢慢减小，而且分布范围也会逐渐减小；</li>
<li>梯度到训练后期比较小甚至接近与0时，这并不一定是梯度消失，可以通过观察loss曲线，发现后期的loss值是也比较小的，因为梯度是loss对param的倒数，所以此时梯度自然也就比较小了。(<strong>感觉这段话讲得好像不对吧，我的理解是：训练后期梯度比较小不仅仅是因为loss值比较小，更重要的是此时loss波动较前期小，即此时的loss相对平滑，这才是造成后期的梯度较小的原因吧。</strong>)</li>
<li>通过观察网络各层参数的梯度，如果发现前面layer的梯度比较小，那么就需要看最后一层的梯度分布情况，如果最后一层的梯度也是比较小的，则这并不是梯度消失现象，因为此时可能是因为loss本身的值就比较低；而如果发现前面layer的梯度较小，而最后一层的梯度较大，则这时候就是梯度消失现象了，因为梯度是从后往前传递的。</li>
</ul>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2019/09/15/PyTorch%E7%AC%94%E8%AE%B0/%E3%80%90Tutorials%E3%80%91TensorBoard-2%20%E7%9B%91%E6%8E%A7loss,acc,grad/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/15/PyTorch%E7%AC%94%E8%AE%B0/%E3%80%90Tutorials%E3%80%91torch.utils.data%20DataLoader%20and%20Dataset/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="其实，我是一个搬运工！">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Paper搬运菌">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2019/09/15/PyTorch%E7%AC%94%E8%AE%B0/%E3%80%90Tutorials%E3%80%91torch.utils.data%20DataLoader%20and%20Dataset/" class="post-title-link" itemprop="url">PyTorch笔记/【Tutorials】torch.utils.data DataLoader and Dataset</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-09-15 00:00:00" itemprop="dateCreated datePublished" datetime="2019-09-15T00:00:00+08:00">2019-09-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-05-27 10:25:42" itemprop="dateModified" datetime="2020-05-27T10:25:42+08:00">2020-05-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/PyTorch%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index">
                    <span itemprop="name">PyTorch笔记</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>本节主要讲述PyTorch中的DataLoader与Dataset的使用，并举代码示例用LeNet做人民币的二分类。<br>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2019/09/15/PyTorch%E7%AC%94%E8%AE%B0/%E3%80%90Tutorials%E3%80%91torch.utils.data%20DataLoader%20and%20Dataset/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/11/PyTorch%E7%AC%94%E8%AE%B0/%E3%80%90Entries%E3%80%91Tensor%20Operation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="其实，我是一个搬运工！">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Paper搬运菌">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2019/09/11/PyTorch%E7%AC%94%E8%AE%B0/%E3%80%90Entries%E3%80%91Tensor%20Operation/" class="post-title-link" itemprop="url">PyTorch笔记/【Entries】Tensor Operation</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-09-11 00:00:00" itemprop="dateCreated datePublished" datetime="2019-09-11T00:00:00+08:00">2019-09-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-05-27 10:25:02" itemprop="dateModified" datetime="2020-05-27T10:25:02+08:00">2020-05-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/PyTorch%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index">
                    <span itemprop="name">PyTorch笔记</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <a id="more"></a>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">torch.cross(input, other, dim=<span class="number">-1</span>, out=<span class="literal">None</span>)  <span class="comment">#叉乘(外积)</span></span><br><span class="line"></span><br><span class="line">torch.dot(tensor1, tensor2)  <span class="comment">#返回tensor1和tensor2的点乘</span></span><br><span class="line"></span><br><span class="line">torch.mm(mat1, mat2, out=<span class="literal">None</span>) <span class="comment">#返回矩阵mat1和mat2的乘积</span></span><br><span class="line">torch.matmul(mat1, mat2, out=<span class="literal">None</span>)  <span class="comment"># 同torch.mm</span></span><br><span class="line"><span class="comment"># 对矩阵`mat1`和`mat2`进行相乘。 如果`mat1` 是一个n×m张量，`mat2` 是一个 m×p 张量，将会输出一个 n×p 张量`out`。</span></span><br><span class="line"></span><br><span class="line">torch.eig(a, eigenvectors=<span class="literal">False</span>, out=<span class="literal">None</span>) <span class="comment">#返回矩阵a的特征值/特征向量 </span></span><br><span class="line"></span><br><span class="line">torch.det(A)  <span class="comment">#返回矩阵A的行列式</span></span><br><span class="line"></span><br><span class="line">torch.trace(input) <span class="comment">#返回2-d 矩阵的迹(对对角元素求和)</span></span><br><span class="line"></span><br><span class="line">torch.diag(input, diagonal=<span class="number">0</span>, out=<span class="literal">None</span>) <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">torch.histc(input, bins=<span class="number">100</span>, min=<span class="number">0</span>, max=<span class="number">0</span>, out=<span class="literal">None</span>) <span class="comment">#计算input的直方图</span></span><br><span class="line"></span><br><span class="line">torch.tril(input, diagonal=<span class="number">0</span>, out=<span class="literal">None</span>)  <span class="comment">#返回矩阵的下三角矩阵，其他为0</span></span><br><span class="line"></span><br><span class="line">torch.triu(input, diagonal=<span class="number">0</span>, out=<span class="literal">None</span>) <span class="comment">#返回矩阵的上三角矩阵，其他为0</span></span><br></pre></td></tr></table></figure>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] <a href="https://zhuanlan.zhihu.com/p/36233589" target="_blank" rel="noopener">pytorch入坑一 | Tensor及其基本操作</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/11/PyTorch%E7%AC%94%E8%AE%B0/%E3%80%90Tutorials%E3%80%91Computational%20Graph/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="其实，我是一个搬运工！">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Paper搬运菌">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2019/09/11/PyTorch%E7%AC%94%E8%AE%B0/%E3%80%90Tutorials%E3%80%91Computational%20Graph/" class="post-title-link" itemprop="url">PyTorch笔记/【Tutorials】Computational Graph</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-09-11 00:00:00" itemprop="dateCreated datePublished" datetime="2019-09-11T00:00:00+08:00">2019-09-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-03-07 17:29:48" itemprop="dateModified" datetime="2020-03-07T17:29:48+08:00">2020-03-07</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/PyTorch%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index">
                    <span itemprop="name">PyTorch笔记</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>本节主要讲述计算图的概念以及tensor的一些属性(is_leaf、grad_fn等)，这些属性在计算图中是非常重要的。<br>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2019/09/11/PyTorch%E7%AC%94%E8%AE%B0/%E3%80%90Tutorials%E3%80%91Computational%20Graph/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/11/PyTorch%E7%AC%94%E8%AE%B0/%E3%80%90Tutorials%E3%80%91Tensor-3%20Linear%20Regression/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="其实，我是一个搬运工！">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Paper搬运菌">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2019/09/11/PyTorch%E7%AC%94%E8%AE%B0/%E3%80%90Tutorials%E3%80%91Tensor-3%20Linear%20Regression/" class="post-title-link" itemprop="url">PyTorch笔记/【Tutorials】Tensor-3 Linear Regression</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-09-11 00:00:00" itemprop="dateCreated datePublished" datetime="2019-09-11T00:00:00+08:00">2019-09-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-03-07 14:26:42" itemprop="dateModified" datetime="2020-03-07T14:26:42+08:00">2020-03-07</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/PyTorch%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index">
                    <span itemprop="name">PyTorch笔记</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>本节主要利用前面讲过的Tensor操作来做一个线性回归算法的示例。<br>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2019/09/11/PyTorch%E7%AC%94%E8%AE%B0/%E3%80%90Tutorials%E3%80%91Tensor-3%20Linear%20Regression/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/11/PyTorch%E7%AC%94%E8%AE%B0/%E3%80%90Tutorials%E3%80%91Tensor-2%20Operation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="其实，我是一个搬运工！">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Paper搬运菌">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2019/09/11/PyTorch%E7%AC%94%E8%AE%B0/%E3%80%90Tutorials%E3%80%91Tensor-2%20Operation/" class="post-title-link" itemprop="url">PyTorch笔记/【Tutorials】Tensor-2 Operation</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-09-11 00:00:00" itemprop="dateCreated datePublished" datetime="2019-09-11T00:00:00+08:00">2019-09-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-03-07 14:20:26" itemprop="dateModified" datetime="2020-03-07T14:20:26+08:00">2020-03-07</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/PyTorch%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index">
                    <span itemprop="name">PyTorch笔记</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>本篇主要介绍tensor的拼接、切分、索引、变换、数学运算。<br>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2019/09/11/PyTorch%E7%AC%94%E8%AE%B0/%E3%80%90Tutorials%E3%80%91Tensor-2%20Operation/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/11/PyTorch%E7%AC%94%E8%AE%B0/%E3%80%90Tutorials%E3%80%91autograd-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="其实，我是一个搬运工！">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Paper搬运菌">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2019/09/11/PyTorch%E7%AC%94%E8%AE%B0/%E3%80%90Tutorials%E3%80%91autograd-1/" class="post-title-link" itemprop="url">PyTorch笔记/【Tutorials】autograd-1</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-09-11 00:00:00" itemprop="dateCreated datePublished" datetime="2019-09-11T00:00:00+08:00">2019-09-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-03-08 09:36:17" itemprop="dateModified" datetime="2020-03-08T09:36:17+08:00">2020-03-08</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/PyTorch%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index">
                    <span itemprop="name">PyTorch笔记</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>本节主要讲述torch.autograd和backward和grad方法，以及关于autograd的一些小贴士<br>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2019/09/11/PyTorch%E7%AC%94%E8%AE%B0/%E3%80%90Tutorials%E3%80%91autograd-1/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/11/PyTorch%E7%AC%94%E8%AE%B0/%E3%80%90Tutorials%E3%80%91autograd-2%20Logistic%20Regression/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="其实，我是一个搬运工！">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Paper搬运菌">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2019/09/11/PyTorch%E7%AC%94%E8%AE%B0/%E3%80%90Tutorials%E3%80%91autograd-2%20Logistic%20Regression/" class="post-title-link" itemprop="url">PyTorch笔记/【Tutorials】autograd-2 Logistic Regression</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-09-11 00:00:00" itemprop="dateCreated datePublished" datetime="2019-09-11T00:00:00+08:00">2019-09-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-03-09 10:37:13" itemprop="dateModified" datetime="2020-03-09T10:37:13+08:00">2020-03-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/PyTorch%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index">
                    <span itemprop="name">PyTorch笔记</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>本节主要讲述逻辑回归模型以及逻辑回归和线性回归之间的关系，并利用上一节中所讲的autograd来做一个逻辑回归算法的示例。<br>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2019/09/11/PyTorch%E7%AC%94%E8%AE%B0/%E3%80%90Tutorials%E3%80%91autograd-2%20Logistic%20Regression/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/03/PyTorch%E7%AC%94%E8%AE%B0/%E3%80%90Tutorials%E3%80%91Learning%20Reat%20Scheduler/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="其实，我是一个搬运工！">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Paper搬运菌">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2019/09/03/PyTorch%E7%AC%94%E8%AE%B0/%E3%80%90Tutorials%E3%80%91Learning%20Reat%20Scheduler/" class="post-title-link" itemprop="url">PyTorch笔记/【Tutorials】Learning Reat Scheduler</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-09-03 00:00:00" itemprop="dateCreated datePublished" datetime="2019-09-03T00:00:00+08:00">2019-09-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-03-07 13:27:19" itemprop="dateModified" datetime="2020-03-07T13:27:19+08:00">2020-03-07</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/PyTorch%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index">
                    <span itemprop="name">PyTorch笔记</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="学习率策略的基类"><a href="#学习率策略的基类" class="headerlink" title="学习率策略的基类"></a>学习率策略的基类</h1><p>pytorch中有6种学习率调整策略，都继承自一个基类 _LRScheduler.<br>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2019/09/03/PyTorch%E7%AC%94%E8%AE%B0/%E3%80%90Tutorials%E3%80%91Learning%20Reat%20Scheduler/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

  </div>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/5/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/">7</a><span class="space">&hellip;</span><a class="page-number" href="/page/15/">15</a><a class="extend next" rel="next" href="/page/7/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name"></p>
  <div class="site-description" itemprop="description">其实，我是一个搬运工！</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">141</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder"></span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.7.0
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  













<script>
if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js', () => {
    mermaid.initialize({
      theme: 'default',
      logLevel: 3,
      flowchart: { curve: 'linear' },
      gantt: { axisFormat: '%m/%d/%Y' },
      sequence: { actorMargin: 50 }
    });
  }, window.mermaid);
}
</script>


  

  
      
<script type="text/x-mathjax-config">
    MathJax.Ajax.config.path['mhchem'] = '//cdn.jsdelivr.net/npm/mathjax-mhchem@3';

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        extensions: ['[mhchem]/mhchem.js'],
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    

  

</body>
</html>
