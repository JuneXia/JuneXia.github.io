<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('http://yoursite.com').hostname,
    root: '/',
    scheme: 'Gemini',
    version: '7.7.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta name="description" content="本节主要讲述FasterRCNN的PyTorch实现代码主要流程。">
<meta property="og:type" content="article">
<meta property="og:title" content="PyTorch笔记&#x2F;【Tutorials】torchvision.models.detection-1 FasterRCNN">
<meta property="og:url" content="http://yoursite.com/2020/03/12/PyTorch%E7%AC%94%E8%AE%B0/%E3%80%90Tutorials%E3%80%91torchvision.models.detection-1%20FasterRCNN/index.html">
<meta property="og:site_name" content="Paper搬运菌">
<meta property="og:description" content="本节主要讲述FasterRCNN的PyTorch实现代码主要流程。">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2020-03-11T16:00:00.000Z">
<meta property="article:modified_time" content="2020-03-29T14:22:07.741Z">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://yoursite.com/2020/03/12/PyTorch%E7%AC%94%E8%AE%B0/%E3%80%90Tutorials%E3%80%91torchvision.models.detection-1%20FasterRCNN/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>PyTorch笔记/【Tutorials】torchvision.models.detection-1 FasterRCNN | Paper搬运菌</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Paper搬运菌</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/03/12/PyTorch%E7%AC%94%E8%AE%B0/%E3%80%90Tutorials%E3%80%91torchvision.models.detection-1%20FasterRCNN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="其实，我是一个搬运工！">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Paper搬运菌">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          PyTorch笔记/【Tutorials】torchvision.models.detection-1 FasterRCNN
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-03-12 00:00:00" itemprop="dateCreated datePublished" datetime="2020-03-12T00:00:00+08:00">2020-03-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-03-29 22:22:07" itemprop="dateModified" datetime="2020-03-29T22:22:07+08:00">2020-03-29</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/PyTorch%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index">
                    <span itemprop="name">PyTorch笔记</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>本节主要讲述FasterRCNN的PyTorch实现代码主要流程。<br><a id="more"></a></p>
<p>下面先看看数据集定义以及训练主函数代码，后面会依次讲解训练过程中的数据读取、FasterRCNN的前向计算过程。</p>
<h1 id="数据集以及训练主函数代码"><a href="#数据集以及训练主函数代码" class="headerlink" title="数据集以及训练主函数代码"></a>数据集以及训练主函数代码</h1><p><strong>dataset.py</strong>:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string"># @file name  : dataset.py</span></span><br><span class="line"><span class="string"># @author     : yts3221@126.com</span></span><br><span class="line"><span class="string"># @date       : 2019-08-21 10:08:00</span></span><br><span class="line"><span class="string"># @brief      : 各数据集的Dataset定义</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"></span><br><span class="line">random.seed(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PennFudanDataset</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, data_dir, transforms)</span>:</span></span><br><span class="line"></span><br><span class="line">        self.data_dir = data_dir</span><br><span class="line">        self.transforms = transforms</span><br><span class="line">        self.img_dir = os.path.join(data_dir, <span class="string">"PNGImages"</span>)</span><br><span class="line">        self.txt_dir = os.path.join(data_dir, <span class="string">"Annotation"</span>)</span><br><span class="line">        self.names = [name[:<span class="number">-4</span>] <span class="keyword">for</span> name <span class="keyword">in</span> list(filter(<span class="keyword">lambda</span> x: x.endswith(<span class="string">".png"</span>), os.listdir(self.img_dir)))]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        返回img和target</span></span><br><span class="line"><span class="string">        :param idx:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line"></span><br><span class="line">        name = self.names[index]</span><br><span class="line">        path_img = os.path.join(self.img_dir, name + <span class="string">".png"</span>)</span><br><span class="line">        path_txt = os.path.join(self.txt_dir, name + <span class="string">".txt"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># load img</span></span><br><span class="line">        img = Image.open(path_img).convert(<span class="string">"RGB"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># load boxes and label</span></span><br><span class="line">        f = open(path_txt, <span class="string">"r"</span>)</span><br><span class="line">        <span class="keyword">import</span> re</span><br><span class="line">        points = [re.findall(<span class="string">r"\d+"</span>, line) <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines() <span class="keyword">if</span> <span class="string">"Xmin"</span> <span class="keyword">in</span> line]</span><br><span class="line">        boxes_list = list()</span><br><span class="line">        <span class="keyword">for</span> point <span class="keyword">in</span> points:</span><br><span class="line">            box = [int(p) <span class="keyword">for</span> p <span class="keyword">in</span> point]</span><br><span class="line">            boxes_list.append(box[<span class="number">-4</span>:])</span><br><span class="line">        boxes = torch.tensor(boxes_list, dtype=torch.float)</span><br><span class="line">        labels = torch.ones((boxes.shape[<span class="number">0</span>],), dtype=torch.long)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># iscrowd = torch.zeros((num_objs,), dtype=torch.int64)</span></span><br><span class="line">        target = &#123;&#125;</span><br><span class="line">        target[<span class="string">"boxes"</span>] = boxes</span><br><span class="line">        target[<span class="string">"labels"</span>] = labels</span><br><span class="line">        <span class="comment"># target["iscrowd"] = iscrowd</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.transforms <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            img, target = self.transforms(img, target)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> img, target</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> len(self.names) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">"\ndata_dir:&#123;&#125; is a empty dir! Please checkout your path to images!"</span>.format(data_dir))</span><br><span class="line">        <span class="keyword">return</span> len(self.names)</span><br></pre></td></tr></table></figure></p>
<p><strong>obj_detect_fasterrcnn</strong>：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string"># @file name  : fasterrcnn_train.py</span></span><br><span class="line"><span class="string"># @author     : TingsongYu https://github.com/TingsongYu</span></span><br><span class="line"><span class="string"># @date       : 2019-11-30</span></span><br><span class="line"><span class="string"># @brief      : 训练faster rcnn</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> tools.my_dataset <span class="keyword">import</span> PennFudanDataset</span><br><span class="line"><span class="keyword">from</span> tools.common_tools <span class="keyword">import</span> set_seed</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> torchvision.models.detection.faster_rcnn <span class="keyword">import</span> FastRCNNPredictor</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line">set_seed(<span class="number">1</span>)  <span class="comment"># 设置随机种子</span></span><br><span class="line"></span><br><span class="line">BASE_DIR = <span class="string">"/home/xiajun/res/person"</span></span><br><span class="line">device = torch.device(<span class="string">"cuda"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># classes_coco</span></span><br><span class="line">COCO_INSTANCE_CATEGORY_NAMES = [</span><br><span class="line">    <span class="string">'__background__'</span>, <span class="string">'person'</span>, <span class="string">'bicycle'</span>, <span class="string">'car'</span>, <span class="string">'motorcycle'</span>, <span class="string">'airplane'</span>, <span class="string">'bus'</span>,</span><br><span class="line">    <span class="string">'train'</span>, <span class="string">'truck'</span>, <span class="string">'boat'</span>, <span class="string">'traffic light'</span>, <span class="string">'fire hydrant'</span>, <span class="string">'N/A'</span>, <span class="string">'stop sign'</span>,</span><br><span class="line">    <span class="string">'parking meter'</span>, <span class="string">'bench'</span>, <span class="string">'bird'</span>, <span class="string">'cat'</span>, <span class="string">'dog'</span>, <span class="string">'horse'</span>, <span class="string">'sheep'</span>, <span class="string">'cow'</span>,</span><br><span class="line">    <span class="string">'elephant'</span>, <span class="string">'bear'</span>, <span class="string">'zebra'</span>, <span class="string">'giraffe'</span>, <span class="string">'N/A'</span>, <span class="string">'backpack'</span>, <span class="string">'umbrella'</span>, <span class="string">'N/A'</span>, <span class="string">'N/A'</span>,</span><br><span class="line">    <span class="string">'handbag'</span>, <span class="string">'tie'</span>, <span class="string">'suitcase'</span>, <span class="string">'frisbee'</span>, <span class="string">'skis'</span>, <span class="string">'snowboard'</span>, <span class="string">'sports ball'</span>,</span><br><span class="line">    <span class="string">'kite'</span>, <span class="string">'baseball bat'</span>, <span class="string">'baseball glove'</span>, <span class="string">'skateboard'</span>, <span class="string">'surfboard'</span>, <span class="string">'tennis racket'</span>,</span><br><span class="line">    <span class="string">'bottle'</span>, <span class="string">'N/A'</span>, <span class="string">'wine glass'</span>, <span class="string">'cup'</span>, <span class="string">'fork'</span>, <span class="string">'knife'</span>, <span class="string">'spoon'</span>, <span class="string">'bowl'</span>,</span><br><span class="line">    <span class="string">'banana'</span>, <span class="string">'apple'</span>, <span class="string">'sandwich'</span>, <span class="string">'orange'</span>, <span class="string">'broccoli'</span>, <span class="string">'carrot'</span>, <span class="string">'hot dog'</span>, <span class="string">'pizza'</span>,</span><br><span class="line">    <span class="string">'donut'</span>, <span class="string">'cake'</span>, <span class="string">'chair'</span>, <span class="string">'couch'</span>, <span class="string">'potted plant'</span>, <span class="string">'bed'</span>, <span class="string">'N/A'</span>, <span class="string">'dining table'</span>,</span><br><span class="line">    <span class="string">'N/A'</span>, <span class="string">'N/A'</span>, <span class="string">'toilet'</span>, <span class="string">'N/A'</span>, <span class="string">'tv'</span>, <span class="string">'laptop'</span>, <span class="string">'mouse'</span>, <span class="string">'remote'</span>, <span class="string">'keyboard'</span>, <span class="string">'cell phone'</span>,</span><br><span class="line">    <span class="string">'microwave'</span>, <span class="string">'oven'</span>, <span class="string">'toaster'</span>, <span class="string">'sink'</span>, <span class="string">'refrigerator'</span>, <span class="string">'N/A'</span>, <span class="string">'book'</span>,</span><br><span class="line">    <span class="string">'clock'</span>, <span class="string">'vase'</span>, <span class="string">'scissors'</span>, <span class="string">'teddy bear'</span>, <span class="string">'hair drier'</span>, <span class="string">'toothbrush'</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vis_bbox</span><span class="params">(img, output, classes, max_vis=<span class="number">40</span>, prob_thres=<span class="number">0.4</span>)</span>:</span></span><br><span class="line">    fig, ax = plt.subplots(figsize=(<span class="number">12</span>, <span class="number">12</span>))</span><br><span class="line">    ax.imshow(img, aspect=<span class="string">'equal'</span>)</span><br><span class="line"></span><br><span class="line">    out_boxes = output_dict[<span class="string">"boxes"</span>].cpu()</span><br><span class="line">    out_scores = output_dict[<span class="string">"scores"</span>].cpu()</span><br><span class="line">    out_labels = output_dict[<span class="string">"labels"</span>].cpu()</span><br><span class="line"></span><br><span class="line">    num_boxes = out_boxes.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> range(<span class="number">0</span>, min(num_boxes, max_vis)):</span><br><span class="line"></span><br><span class="line">        score = out_scores[idx].numpy()</span><br><span class="line">        bbox = out_boxes[idx].numpy()</span><br><span class="line">        class_name = classes[out_labels[idx]]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> score &lt; prob_thres:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        ax.add_patch(plt.Rectangle((bbox[<span class="number">0</span>], bbox[<span class="number">1</span>]), bbox[<span class="number">2</span>] - bbox[<span class="number">0</span>], bbox[<span class="number">3</span>] - bbox[<span class="number">1</span>], fill=<span class="literal">False</span>,</span><br><span class="line">                                   edgecolor=<span class="string">'red'</span>, linewidth=<span class="number">3.5</span>))</span><br><span class="line">        ax.text(bbox[<span class="number">0</span>], bbox[<span class="number">1</span>] - <span class="number">2</span>, <span class="string">'&#123;:s&#125; &#123;:.3f&#125;'</span>.format(class_name, score), bbox=dict(facecolor=<span class="string">'blue'</span>, alpha=<span class="number">0.5</span>),</span><br><span class="line">                fontsize=<span class="number">14</span>, color=<span class="string">'white'</span>)</span><br><span class="line">    plt.show()</span><br><span class="line">    plt.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Compose</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, transforms)</span>:</span></span><br><span class="line">        self.transforms = transforms</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, image, target)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> self.transforms:</span><br><span class="line">            image, target = t(image, target)</span><br><span class="line">        <span class="keyword">return</span> image, target</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RandomHorizontalFlip</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, prob)</span>:</span></span><br><span class="line">        self.prob = prob</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, image, target)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> random.random() &lt; self.prob:</span><br><span class="line">            height, width = image.shape[<span class="number">-2</span>:]</span><br><span class="line">            image = image.flip(<span class="number">-1</span>)</span><br><span class="line">            bbox = target[<span class="string">"boxes"</span>]</span><br><span class="line">            bbox[:, [<span class="number">0</span>, <span class="number">2</span>]] = width - bbox[:, [<span class="number">2</span>, <span class="number">0</span>]]</span><br><span class="line">            target[<span class="string">"boxes"</span>] = bbox</span><br><span class="line">        <span class="keyword">return</span> image, target</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ToTensor</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, image, target)</span>:</span></span><br><span class="line">        image = F.to_tensor(image)</span><br><span class="line">        <span class="keyword">return</span> image, target</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line"></span><br><span class="line">    <span class="comment"># config</span></span><br><span class="line">    LR = <span class="number">0.001</span></span><br><span class="line">    num_classes = <span class="number">2</span></span><br><span class="line">    batch_size = <span class="number">2</span></span><br><span class="line">    start_epoch, max_epoch = <span class="number">0</span>, <span class="number">30</span></span><br><span class="line">    train_dir = os.path.join(BASE_DIR, <span class="string">"PennFudanPed"</span>)</span><br><span class="line">    train_transform = Compose([ToTensor(), RandomHorizontalFlip(<span class="number">0.5</span>)])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># step 1: data</span></span><br><span class="line">    train_set = PennFudanDataset(data_dir=train_dir, transforms=train_transform)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 收集batch data的函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">collate_fn</span><span class="params">(batch)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> tuple(zip(*batch))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    train_loader = DataLoader(train_set, batch_size=batch_size, collate_fn=collate_fn)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># step 2: model</span></span><br><span class="line">    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=<span class="literal">True</span>)</span><br><span class="line">    in_features = model.roi_heads.box_predictor.cls_score.in_features</span><br><span class="line">    model.roi_heads.box_predictor = FastRCNNPredictor(in_features,</span><br><span class="line">                                                      num_classes)  <span class="comment"># replace the pre-trained head with a new one</span></span><br><span class="line"></span><br><span class="line">    model.to(device)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># step 3: loss</span></span><br><span class="line">    <span class="comment"># in lib/python3.6/site-packages/torchvision/models/detection/roi_heads.py</span></span><br><span class="line">    <span class="comment"># def fastrcnn_loss(class_logits, box_regression, labels, regression_targets)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># step 4: optimizer scheduler</span></span><br><span class="line">    params = [p <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters() <span class="keyword">if</span> p.requires_grad]</span><br><span class="line">    optimizer = torch.optim.SGD(params, lr=LR, momentum=<span class="number">0.9</span>, weight_decay=<span class="number">0.0005</span>)</span><br><span class="line">    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=<span class="number">10</span>, gamma=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># step 5: Iteration</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(start_epoch, max_epoch):</span><br><span class="line"></span><br><span class="line">        model.train()</span><br><span class="line">        <span class="keyword">for</span> iter, (images, targets) <span class="keyword">in</span> enumerate(train_loader):</span><br><span class="line">            images = list(image.to(device) <span class="keyword">for</span> image <span class="keyword">in</span> images)</span><br><span class="line">            targets = [&#123;k: v.to(device) <span class="keyword">for</span> k, v <span class="keyword">in</span> t.items()&#125; <span class="keyword">for</span> t <span class="keyword">in</span> targets]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># if torch.cuda.is_available():</span></span><br><span class="line">            <span class="comment">#     images, targets = images.to(device), targets.to(device)</span></span><br><span class="line"></span><br><span class="line">            loss_dict = model(images, targets)  <span class="comment"># images is list; targets is [ dict["boxes":**, "labels":**], dict[] ]</span></span><br><span class="line"></span><br><span class="line">            losses = sum(loss <span class="keyword">for</span> loss <span class="keyword">in</span> loss_dict.values())</span><br><span class="line"></span><br><span class="line">            print(<span class="string">"Training:Epoch[&#123;:0&gt;3&#125;/&#123;:0&gt;3&#125;] Iteration[&#123;:0&gt;3&#125;/&#123;:0&gt;3&#125;] Loss: &#123;:.4f&#125; "</span>.format(</span><br><span class="line">                epoch, max_epoch, iter + <span class="number">1</span>, len(train_loader), losses.item()))</span><br><span class="line"></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            losses.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">        lr_scheduler.step()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># test</span></span><br><span class="line">    model.eval()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># config</span></span><br><span class="line">    vis_num = <span class="number">5</span></span><br><span class="line">    vis_dir = os.path.join(BASE_DIR, <span class="string">"PennFudanPed"</span>, <span class="string">"PNGImages"</span>)</span><br><span class="line">    img_names = list(filter(<span class="keyword">lambda</span> x: x.endswith(<span class="string">".png"</span>), os.listdir(vis_dir)))</span><br><span class="line">    random.shuffle(img_names)</span><br><span class="line">    preprocess = transforms.Compose([transforms.ToTensor(), ])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, vis_num):</span><br><span class="line"></span><br><span class="line">        path_img = os.path.join(vis_dir, img_names[i])</span><br><span class="line">        <span class="comment"># preprocess</span></span><br><span class="line">        input_image = Image.open(path_img).convert(<span class="string">"RGB"</span>)</span><br><span class="line">        img_chw = preprocess(input_image)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># to device</span></span><br><span class="line">        <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">            img_chw = img_chw.to(<span class="string">'cuda'</span>)</span><br><span class="line">            model.to(<span class="string">'cuda'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># forward</span></span><br><span class="line">        input_list = [img_chw]</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            tic = time.time()</span><br><span class="line">            print(<span class="string">"input img tensor shape:&#123;&#125;"</span>.format(input_list[<span class="number">0</span>].shape))</span><br><span class="line">            output_list = model(input_list)</span><br><span class="line">            output_dict = output_list[<span class="number">0</span>]</span><br><span class="line">            print(<span class="string">"pass: &#123;:.3f&#125;s"</span>.format(time.time() - tic))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># visualization</span></span><br><span class="line">        vis_bbox(input_image, output_dict, COCO_INSTANCE_CATEGORY_NAMES, max_vis=<span class="number">20</span>,</span><br><span class="line">                 prob_thres=<span class="number">0.5</span>)  <span class="comment"># for 2 epoch for nms</span></span><br></pre></td></tr></table></figure></p>
<hr>
<p>下面开始讲FasterRCNN相关的代码。</p>
<h1 id="模型定义"><a href="#模型定义" class="headerlink" title="模型定义"></a>模型定义</h1><p>torchvision.models.detection.faster_rcnn.py<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fasterrcnn_resnet50_fpn</span><span class="params">(pretrained=False, progress=True,</span></span></span><br><span class="line"><span class="function"><span class="params">                            num_classes=<span class="number">91</span>, pretrained_backbone=True, **kwargs)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        <span class="comment"># no need to download the backbone if pretrained is set</span></span><br><span class="line">        pretrained_backbone = <span class="literal">False</span></span><br><span class="line">    backbone = resnet_fpn_backbone(<span class="string">'resnet50'</span>, pretrained_backbone)</span><br><span class="line">    model = FasterRCNN(backbone, num_classes, **kwargs)</span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        state_dict = load_state_dict_from_url(model_urls[<span class="string">'fasterrcnn_resnet50_fpn_coco'</span>],</span><br><span class="line">                                              progress=progress)</span><br><span class="line">        model.load_state_dict(state_dict)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure></p>
<p>fasterrcnn_resnet50_fpn 中首先得到一个带有fpn的backbone，这个后面细说，TODO.</p>
<p>然后使用刚刚定义的backbone再建一个FasterRCNN实例，FasterRCNN继承自GeneralizedRCNN，FasterRCNN只有<code>__init__</code>函数，它会调用父类的 <code>forward</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FasterRCNN</span><span class="params">(GeneralizedRCNN)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, backbone, num_classes=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                 <span class="comment"># transform parameters</span></span></span></span><br><span class="line"><span class="function"><span class="params">                 min_size=<span class="number">800</span>, max_size=<span class="number">1333</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 image_mean=None, image_std=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                 <span class="comment"># RPN parameters</span></span></span></span><br><span class="line"><span class="function"><span class="params">                 rpn_anchor_generator=None, rpn_head=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                 rpn_pre_nms_top_n_train=<span class="number">2000</span>, rpn_pre_nms_top_n_test=<span class="number">1000</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 rpn_post_nms_top_n_train=<span class="number">2000</span>, rpn_post_nms_top_n_test=<span class="number">1000</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 rpn_nms_thresh=<span class="number">0.7</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 rpn_fg_iou_thresh=<span class="number">0.7</span>, rpn_bg_iou_thresh=<span class="number">0.3</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 rpn_batch_size_per_image=<span class="number">256</span>, rpn_positive_fraction=<span class="number">0.5</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 <span class="comment"># Box parameters</span></span></span></span><br><span class="line"><span class="function"><span class="params">                 box_roi_pool=None, box_head=None, box_predictor=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                 box_score_thresh=<span class="number">0.05</span>, box_nms_thresh=<span class="number">0.5</span>, box_detections_per_img=<span class="number">100</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 box_fg_iou_thresh=<span class="number">0.5</span>, box_bg_iou_thresh=<span class="number">0.5</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 box_batch_size_per_image=<span class="number">512</span>, box_positive_fraction=<span class="number">0.25</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 bbox_reg_weights=None)</span>:</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> hasattr(backbone, <span class="string">"out_channels"</span>):</span><br><span class="line">            <span class="keyword">raise</span> ValueError(</span><br><span class="line">                <span class="string">"backbone should contain an attribute out_channels "</span></span><br><span class="line">                <span class="string">"specifying the number of output channels (assumed to be the "</span></span><br><span class="line">                <span class="string">"same for all the levels)"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> isinstance(rpn_anchor_generator, (AnchorGenerator, type(<span class="literal">None</span>)))</span><br><span class="line">        <span class="keyword">assert</span> isinstance(box_roi_pool, (MultiScaleRoIAlign, type(<span class="literal">None</span>)))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> num_classes <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">if</span> box_predictor <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">"num_classes should be None when box_predictor is specified"</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> box_predictor <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">"num_classes should not be None when box_predictor "</span></span><br><span class="line">                                 <span class="string">"is not specified"</span>)</span><br><span class="line"></span><br><span class="line">        out_channels = backbone.out_channels</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> rpn_anchor_generator <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            anchor_sizes = ((<span class="number">32</span>,), (<span class="number">64</span>,), (<span class="number">128</span>,), (<span class="number">256</span>,), (<span class="number">512</span>,))</span><br><span class="line">            aspect_ratios = ((<span class="number">0.5</span>, <span class="number">1.0</span>, <span class="number">2.0</span>),) * len(anchor_sizes)</span><br><span class="line">            rpn_anchor_generator = AnchorGenerator(</span><br><span class="line">                anchor_sizes, aspect_ratios</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">if</span> rpn_head <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            rpn_head = RPNHead(</span><br><span class="line">                out_channels, rpn_anchor_generator.num_anchors_per_location()[<span class="number">0</span>]</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        rpn_pre_nms_top_n = dict(training=rpn_pre_nms_top_n_train, testing=rpn_pre_nms_top_n_test)</span><br><span class="line">        rpn_post_nms_top_n = dict(training=rpn_post_nms_top_n_train, testing=rpn_post_nms_top_n_test)</span><br><span class="line"></span><br><span class="line">        rpn = RegionProposalNetwork(</span><br><span class="line">            rpn_anchor_generator, rpn_head,</span><br><span class="line">            rpn_fg_iou_thresh, rpn_bg_iou_thresh,</span><br><span class="line">            rpn_batch_size_per_image, rpn_positive_fraction,</span><br><span class="line">            rpn_pre_nms_top_n, rpn_post_nms_top_n, rpn_nms_thresh)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> box_roi_pool <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            box_roi_pool = MultiScaleRoIAlign(</span><br><span class="line">                featmap_names=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">                output_size=<span class="number">7</span>,</span><br><span class="line">                sampling_ratio=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> box_head <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            resolution = box_roi_pool.output_size[<span class="number">0</span>]</span><br><span class="line">            representation_size = <span class="number">1024</span></span><br><span class="line">            box_head = TwoMLPHead(</span><br><span class="line">                out_channels * resolution ** <span class="number">2</span>,</span><br><span class="line">                representation_size)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> box_predictor <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            representation_size = <span class="number">1024</span></span><br><span class="line">            box_predictor = FastRCNNPredictor(</span><br><span class="line">                representation_size,</span><br><span class="line">                num_classes)</span><br><span class="line"></span><br><span class="line">        roi_heads = RoIHeads(</span><br><span class="line">            <span class="comment"># Box</span></span><br><span class="line">            box_roi_pool, box_head, box_predictor,</span><br><span class="line">            box_fg_iou_thresh, box_bg_iou_thresh,</span><br><span class="line">            box_batch_size_per_image, box_positive_fraction,</span><br><span class="line">            bbox_reg_weights,</span><br><span class="line">            box_score_thresh, box_nms_thresh, box_detections_per_img)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> image_mean <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            image_mean = [<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>]</span><br><span class="line">        <span class="keyword">if</span> image_std <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            image_std = [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]</span><br><span class="line">        transform = GeneralizedRCNNTransform(min_size, max_size, image_mean, image_std)</span><br><span class="line"></span><br><span class="line">        super(FasterRCNN, self).__init__(backbone, rpn, roi_heads, transform)</span><br></pre></td></tr></table></figure>
<h1 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h1><p><code>for iter, (images, targets) in enumerate(train_loader):</code></p>
<h2 id="从-Dataset-取样本"><a href="#从-Dataset-取样本" class="headerlink" title="从 Dataset 取样本"></a>从 Dataset 取样本</h2><p>DataLoader 的迭代器在内部每次会从 PennFudanDataset 取出一个样本（一个 batch 会取 batch_size 次）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PennFudanDataset</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, data_dir, transforms)</span>:</span></span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line">        img = Image.open(path_img).convert(<span class="string">"RGB"</span>)</span><br><span class="line"></span><br><span class="line">        target = &#123;&#125;</span><br><span class="line">        target[<span class="string">"boxes"</span>] = boxes</span><br><span class="line">        target[<span class="string">"labels"</span>] = labels</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.transforms <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            img, target = self.transforms(img, target)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> img, target</span><br></pre></td></tr></table></figure>
<h2 id="Dataset-每次会返回一个-tuple："><a href="#Dataset-每次会返回一个-tuple：" class="headerlink" title="Dataset 每次会返回一个 tuple："></a>Dataset 每次会返回一个 tuple：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一张图片所对应的 tensor 和 bboxes、labels</span></span><br><span class="line">(</span><br><span class="line">    tensor([...]),  <span class="comment"># 一个 shape 为[c, h, w]的张量</span></span><br><span class="line"></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">'boxes'</span>: tensor([[<span class="number">355.</span>, <span class="number">135.</span>, <span class="number">490.</span>, <span class="number">389.</span>], [<span class="number">158.</span>, <span class="number">123.</span>, <span class="number">303.</span>, <span class="number">421.</span>]]),  <span class="comment"># shape 为 [n, 4] 的 bboxes</span></span><br><span class="line">        <span class="string">'labels'</span>: tensor([<span class="number">1</span>, <span class="number">1</span>]) <span class="comment"># shape 为 [n, ] 的 labels</span></span><br><span class="line">    &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h2 id="DataLoader-将这些-tuple-组成一个-list"><a href="#DataLoader-将这些-tuple-组成一个-list" class="headerlink" title="DataLoader 将这些 tuple 组成一个 list"></a>DataLoader 将这些 tuple 组成一个 list</h2><p>当 DataLoader 取完 batch_size 个样本后，将这些 tuple 组成一个 list</p>
<p>在目标检测中，由于每张图片大小不一样，所以没法用 shape 为 [b, c, h, w] 的4维tensor来表示一个batch的数据了。<br>以batch_size=2为例，在目标检测中，一个batch的数据形式如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">    <span class="comment"># 第一张图片所对应的 tensor 和 bboxes、labels</span></span><br><span class="line">    (</span><br><span class="line">        tensor([...]),  <span class="comment"># 一个 shape 为[c, h, w]的张量</span></span><br><span class="line"></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">'boxes'</span>: tensor([[<span class="number">355.</span>, <span class="number">135.</span>, <span class="number">490.</span>, <span class="number">389.</span>], [<span class="number">158.</span>, <span class="number">123.</span>, <span class="number">303.</span>, <span class="number">421.</span>]]),  <span class="comment"># shape 为 [n, 4] 的 bboxes</span></span><br><span class="line">            <span class="string">'labels'</span>: tensor([<span class="number">1</span>, <span class="number">1</span>])  <span class="comment"># shape 为 [n, ] 的 labels</span></span><br><span class="line">        &#125;</span><br><span class="line">    ),</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第二张图片所对应的 tensor 和 bboxes、labels</span></span><br><span class="line">    (</span><br><span class="line">        tensor([...]),  <span class="comment"># 一个 shape 为[c, h, w]的张量</span></span><br><span class="line"></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">'boxes'</span>: tensor([[<span class="number">355.</span>, <span class="number">135.</span>, <span class="number">490.</span>, <span class="number">389.</span>], [<span class="number">158.</span>, <span class="number">123.</span>, <span class="number">303.</span>, <span class="number">421.</span>]]), </span><br><span class="line">            <span class="string">'labels'</span>: tensor([<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">        &#125;</span><br><span class="line">    ),</span><br><span class="line">]</span><br></pre></td></tr></table></figure></p>
<h2 id="DataLoader-调用用户自定义的-collate-fn-将这个-list-重组成如下形式："><a href="#DataLoader-调用用户自定义的-collate-fn-将这个-list-重组成如下形式：" class="headerlink" title="DataLoader 调用用户自定义的 collate_fn 将这个 list 重组成如下形式："></a>DataLoader 调用用户自定义的 <code>collate_fn</code> 将这个 list 重组成如下形式：</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">(</span><br><span class="line">    # 这一个tuple对应的是images</span><br><span class="line">    (</span><br><span class="line">        tensor([...]),</span><br><span class="line">        tensor([...])</span><br><span class="line">    ),</span><br><span class="line"></span><br><span class="line">    # 这一个tuple对应的是targets</span><br><span class="line">    (</span><br><span class="line">        &#123;</span><br><span class="line">            &#39;boxes&#39;: tensor([[355., 135., 490., 389.], [158., 123., 303., 421.]]), </span><br><span class="line">            &#39;labels&#39;: tensor([1, 1])</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &#39;boxes&#39;: tensor([[ 15.,  29., 124., 325.], [169.,  27., 266., 329.]]), </span><br><span class="line">            &#39;labels&#39;: tensor([1, 1])</span><br><span class="line">        &#125;</span><br><span class="line">    )</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>至此，数据还是在 CPU 上</p>
<h2 id="现在可以将这些数据搬运到-GPU-上了"><a href="#现在可以将这些数据搬运到-GPU-上了" class="headerlink" title="现在可以将这些数据搬运到 GPU 上了"></a>现在可以将这些数据搬运到 GPU 上了</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> iter, (images, targets) <span class="keyword">in</span> enumerate(train_loader):</span><br><span class="line">    images = list(image.to(device) <span class="keyword">for</span> image <span class="keyword">in</span> images)</span><br><span class="line">    targets = [&#123;k: v.to(device) <span class="keyword">for</span> k, v <span class="keyword">in</span> t.items()&#125; <span class="keyword">for</span> t <span class="keyword">in</span> targets]</span><br></pre></td></tr></table></figure>
<h1 id="开始网络前向计算"><a href="#开始网络前向计算" class="headerlink" title="开始网络前向计算"></a>开始网络前向计算</h1><p>执行 <code>model(images, target)</code> 进入 FasterRCNN 的 forward 函数（这里实际上是 GeneralizedRCNN 的 forward 函数），\<br>在 GeneralizedRCNN 的 forward 函数中，首先是要对传入的images和targets做transform操作。</p>
<h2 id="对images和targets做transform操作"><a href="#对images和targets做transform操作" class="headerlink" title="对images和targets做transform操作"></a>对images和targets做transform操作</h2><p>先贴出这段的全局代码，后面再依次详细介绍。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GeneralizedRCNNTransform</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Performs input / target transformation before feeding the data to a GeneralizedRCNN</span></span><br><span class="line"><span class="string">    model.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    The transformations it perform are:</span></span><br><span class="line"><span class="string">        - input normalization (mean subtraction and std division)</span></span><br><span class="line"><span class="string">        - input / target resizing to match min_size / max_size</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    It returns a ImageList for the inputs, and a List[Dict[Tensor]] for the targets</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, min_size, max_size, image_mean, image_std)</span>:</span></span><br><span class="line">        super(GeneralizedRCNNTransform, self).__init__()</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> isinstance(min_size, (list, tuple)):</span><br><span class="line">            min_size = (min_size,)</span><br><span class="line">        self.min_size = min_size</span><br><span class="line">        self.max_size = max_size</span><br><span class="line">        self.image_mean = image_mean</span><br><span class="line">        self.image_std = image_std</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, images, targets=None)</span>:</span></span><br><span class="line">        images = [img <span class="keyword">for</span> img <span class="keyword">in</span> images]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(images)):</span><br><span class="line">            image = images[i]</span><br><span class="line">            target = targets[i] <span class="keyword">if</span> targets <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> targets</span><br><span class="line">            <span class="keyword">if</span> image.dim() != <span class="number">3</span>:</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">"images is expected to be a list of 3d tensors "</span></span><br><span class="line">                                 <span class="string">"of shape [C, H, W], got &#123;&#125;"</span>.format(image.shape))</span><br><span class="line">            image = self.normalize(image)</span><br><span class="line">            image, target = self.resize(image, target)</span><br><span class="line">            images[i] = image</span><br><span class="line">            <span class="keyword">if</span> targets <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                targets[i] = target</span><br><span class="line"></span><br><span class="line">        image_sizes = [img.shape[<span class="number">-2</span>:] <span class="keyword">for</span> img <span class="keyword">in</span> images]</span><br><span class="line">        images = self.batch_images(images)</span><br><span class="line">        image_list = ImageList(images, image_sizes)</span><br><span class="line">        <span class="keyword">return</span> image_list, targets</span><br></pre></td></tr></table></figure></p>
<h3 id="在for循环中对每张image和其对应的target做normalize和resize操作"><a href="#在for循环中对每张image和其对应的target做normalize和resize操作" class="headerlink" title="在for循环中对每张image和其对应的target做normalize和resize操作"></a>在for循环中对每张image和其对应的target做normalize和resize操作</h3><h4 id="依次对images中的每张image做normalize操作"><a href="#依次对images中的每张image做normalize操作" class="headerlink" title="依次对images中的每张image做normalize操作"></a>依次对images中的每张image做normalize操作</h4><p>依次对images中的每张image(其实是一个tensor)做normalize操作.</p>
<p>torchvision.models.detection.transform.py<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GeneralizedRCNNTransform</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">normalize</span><span class="params">(self, image)</span>:</span></span><br><span class="line">        dtype, device = image.dtype, image.device</span><br><span class="line">        mean = torch.as_tensor(self.image_mean, dtype=dtype, device=device)</span><br><span class="line">        std = torch.as_tensor(self.image_std, dtype=dtype, device=device)</span><br><span class="line">        <span class="keyword">return</span> (image - mean[:, <span class="literal">None</span>, <span class="literal">None</span>]) / std[:, <span class="literal">None</span>, <span class="literal">None</span>]</span><br></pre></td></tr></table></figure><br>计算公式如下：</p>
<script type="math/tex; mode=display">
\begin{aligned}
    image\_mean &= [0.485, 0.456, 0.406] \\
    image\_std &= [0.229, 0.224, 0.225] \\
image[i, ...] &= \frac{image[i, ...] - mean[i]}{std[i]}, \qquad i \in \{ 0, 1, 2 \}
\end{aligned}</script><p>上面 image_mean 和 image_std 的值是默认的值，当然用户也可以自己定义。</p>
<h4 id="依次对images和targets做resize操作"><a href="#依次对images和targets做resize操作" class="headerlink" title="依次对images和targets做resize操作"></a>依次对images和targets做resize操作</h4><p>本小节的完整代码如下：<br>torchvision.models.detection.transform.py<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GeneralizedRCNNTransform</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">resize</span><span class="params">(self, image, target)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.training:</span><br><span class="line">            random_size = random.choice(self.min_size)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># FIXME assume for now that testing uses the largest scale</span></span><br><span class="line">            random_size = self.min_size[<span class="number">-1</span>]</span><br><span class="line">        scale_factor = 根据 random_size 和 image 尺寸生成合适的缩放比例</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 开始缩放图片，保持 image 长宽比不变</span></span><br><span class="line">        image = torch.nn.functional.interpolate(</span><br><span class="line">            image[<span class="literal">None</span>], scale_factor=scale_factor, mode=<span class="string">'bilinear'</span>, align_corners=<span class="literal">False</span>)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> target <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> image, target</span><br><span class="line"></span><br><span class="line">        bbox = target[<span class="string">"boxes"</span>]</span><br><span class="line">        bbox = resize_boxes(bbox, (h, w), image.shape[<span class="number">-2</span>:])</span><br><span class="line">        target[<span class="string">"boxes"</span>] = bbox</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="string">"masks"</span> <span class="keyword">in</span> target:</span><br><span class="line">            mask = target[<span class="string">"masks"</span>]</span><br><span class="line">            mask = misc_nn_ops.interpolate(mask[<span class="literal">None</span>].float(), scale_factor=scale_factor)[<span class="number">0</span>].byte()</span><br><span class="line">            target[<span class="string">"masks"</span>] = mask</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="string">"keypoints"</span> <span class="keyword">in</span> target:</span><br><span class="line">            keypoints = target[<span class="string">"keypoints"</span>]</span><br><span class="line">            keypoints = resize_keypoints(keypoints, (h, w), image.shape[<span class="number">-2</span>:])</span><br><span class="line">            target[<span class="string">"keypoints"</span>] = keypoints</span><br><span class="line">        <span class="keyword">return</span> image, target</span><br></pre></td></tr></table></figure></p>
<h5 id="将每张图片-tensor-缩放到一个随机选中的尺度"><a href="#将每张图片-tensor-缩放到一个随机选中的尺度" class="headerlink" title="将每张图片(tensor)缩放到一个随机选中的尺度"></a>将每张图片(tensor)缩放到一个随机选中的尺度</h5><p>在训练阶段，是先从 <code>self.min_size</code>(一个<code>tuple</code>) 中随机选择一个尺寸，然后将图片(tensor)保持宽高比不变缩放到这个选中的尺寸。</p>
<h5 id="将图片对应的-ground-turth-也要缩放到这个尺度"><a href="#将图片对应的-ground-turth-也要缩放到这个尺度" class="headerlink" title="将图片对应的 ground_turth 也要缩放到这个尺度"></a>将图片对应的 ground_turth 也要缩放到这个尺度</h5><p>torchvision.models.detection.transform.py<br>对于目标检测任务来说，图片被缩放了，ground_turth 肯定也得跟着缩放<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resize_boxes</span><span class="params">(boxes, original_size, new_size)</span>:</span></span><br><span class="line">    ratios = tuple(float(s) / float(s_orig) <span class="keyword">for</span> s, s_orig <span class="keyword">in</span> zip(new_size, original_size))</span><br><span class="line">    ratio_height, ratio_width = ratios</span><br><span class="line">    xmin, ymin, xmax, ymax = boxes.unbind(<span class="number">1</span>)</span><br><span class="line">    xmin = xmin * ratio_width</span><br><span class="line">    xmax = xmax * ratio_width</span><br><span class="line">    ymin = ymin * ratio_height</span><br><span class="line">    ymax = ymax * ratio_height</span><br><span class="line">    <span class="keyword">return</span> torch.stack((xmin, ymin, xmax, ymax), dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure></p>
<h5 id="如果有masks或者keypoints，也要做相应的缩放"><a href="#如果有masks或者keypoints，也要做相应的缩放" class="headerlink" title="如果有masks或者keypoints，也要做相应的缩放"></a>如果有masks或者keypoints，也要做相应的缩放</h5><p>略 ……</p>
<h3 id="提取images中每个tensor的尺寸并存入一个局部变量-image-sizes-中"><a href="#提取images中每个tensor的尺寸并存入一个局部变量-image-sizes-中" class="headerlink" title="提取images中每个tensor的尺寸并存入一个局部变量 image_sizes 中"></a>提取images中每个tensor的尺寸并存入一个局部变量 image_sizes 中</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">image_sizes = [img.shape[<span class="number">-2</span>:] <span class="keyword">for</span> img <span class="keyword">in</span> images]</span><br></pre></td></tr></table></figure>
<h3 id="将list形式的images重组为一个4维tensor"><a href="#将list形式的images重组为一个4维tensor" class="headerlink" title="将list形式的images重组为一个4维tensor"></a>将list形式的images重组为一个4维tensor</h3><p>torchvision.models.detection.transform.py<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GeneralizedRCNNTransform</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">batch_images</span><span class="params">(self, images, size_divisible=<span class="number">32</span>)</span>:</span></span><br><span class="line">        <span class="comment"># concatenate</span></span><br><span class="line">        max_size = tuple(max(s) <span class="keyword">for</span> s <span class="keyword">in</span> zip(*[img.shape <span class="keyword">for</span> img <span class="keyword">in</span> images]))</span><br><span class="line"></span><br><span class="line">        stride = size_divisible</span><br><span class="line">        max_size = list(max_size)</span><br><span class="line">        max_size[<span class="number">1</span>] = int(math.ceil(float(max_size[<span class="number">1</span>]) / stride) * stride)</span><br><span class="line">        max_size[<span class="number">2</span>] = int(math.ceil(float(max_size[<span class="number">2</span>]) / stride) * stride)</span><br><span class="line">        max_size = tuple(max_size)</span><br><span class="line"></span><br><span class="line">        batch_shape = (len(images),) + max_size</span><br><span class="line">        batched_imgs = images[<span class="number">0</span>].new(*batch_shape).zero_()</span><br><span class="line">        <span class="keyword">for</span> img, pad_img <span class="keyword">in</span> zip(images, batched_imgs):</span><br><span class="line">            pad_img[: img.shape[<span class="number">0</span>], : img.shape[<span class="number">1</span>], : img.shape[<span class="number">2</span>]].copy_(img)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> batched_imgs</span><br></pre></td></tr></table></figure><br>将images中的每个tensor(3维)通过pading操作重组为一个4维的tensor.</p>
<h3 id="将此时的images-此时已是4维tensor-和image-sizes都用-ImageList-封装一下"><a href="#将此时的images-此时已是4维tensor-和image-sizes都用-ImageList-封装一下" class="headerlink" title="将此时的images(此时已是4维tensor)和image_sizes都用 ImageList 封装一下"></a>将此时的images(此时已是4维tensor)和image_sizes都用 ImageList 封装一下</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ImageList</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Structure that holds a list of images (of possibly</span></span><br><span class="line"><span class="string">    varying sizes) as a single tensor.</span></span><br><span class="line"><span class="string">    This works by padding the images to the same size,</span></span><br><span class="line"><span class="string">    and storing in a field the original sizes of each image</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, tensors, image_sizes)</span>:</span></span><br><span class="line">        self.tensors = tensors</span><br><span class="line">        self.image_sizes = image_sizes</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">to</span><span class="params">(self, *args, **kwargs)</span>:</span></span><br><span class="line">        cast_tensor = self.tensors.to(*args, **kwargs)</span><br><span class="line">        <span class="keyword">return</span> ImageList(cast_tensor, self.image_sizes)</span><br></pre></td></tr></table></figure>
<h3 id="transform-forward-返回-image-list-和-targets"><a href="#transform-forward-返回-image-list-和-targets" class="headerlink" title="transform forward 返回 image_list 和 targets"></a>transform forward 返回 image_list 和 targets</h3><p>如题…</p>
<h3 id="transform-总结"><a href="#transform-总结" class="headerlink" title="transform 总结"></a>transform 总结</h3><p>我们现在小结下上面的 transform 操作，该操作传入两个参数images和targets，且它们都是list，\<br>在 transform 中首先会进入一个for循环，在for循环中对每个image做normalize操作，然后再做resize操作，当然和其对应的target也要resize(在resize操作会将它们保持宽高比地resize到一个随机选中的尺寸)。\<br>for循环出来后得到的还是images和targets，且这时候它们还是list. \<br>提取images中每个tensor的尺寸并存入一个局部变量 image_sizes 中. \<br>将images中的每个tensor(3维)通过pading操作重组为一个4维的tensor. \<br>将此时的images(此时已是4维tensor)和image_sizes都用 ImageList 封装一下得到一个 image_list. \<br>forward 返回 (image_list, targets)</p>
<h2 id="backbone"><a href="#backbone" class="headerlink" title="backbone"></a>backbone</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">features = self.backbone(images.tensors)</span><br></pre></td></tr></table></figure>
<p>将 images.tensors(4维tensor) 传入 backbone 得到一个有序字典 features（features 是一个 OrderedDict，有序字典）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(features.keys())</span><br><span class="line">odict_keys([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="string">'pool'</span>])</span><br></pre></td></tr></table></figure>
<h2 id="rpn"><a href="#rpn" class="headerlink" title="rpn"></a>rpn</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">proposals, proposal_losses = self.rpn(images, features, targets)</span><br></pre></td></tr></table></figure>
<h3 id="执行-RPNHead-操作"><a href="#执行-RPNHead-操作" class="headerlink" title="执行 RPNHead 操作"></a>执行 RPNHead 操作</h3><p><strong>调用代码</strong>：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">features = list(features.values())</span><br><span class="line">objectness, pred_bbox_deltas = self.head(features)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># output:</span></span><br><span class="line"><span class="keyword">for</span> i, (obj, box) <span class="keyword">in</span> enumerate(zip(objectness, pred_bbox_deltas)):</span><br><span class="line">    print(i, obj.shape, box.shape)</span><br><span class="line">    </span><br><span class="line"><span class="number">0</span> torch.Size([<span class="number">2</span>, <span class="number">3</span>, <span class="number">200</span>, <span class="number">232</span>]) torch.Size([<span class="number">2</span>, <span class="number">12</span>, <span class="number">200</span>, <span class="number">232</span>])</span><br><span class="line"><span class="number">1</span> torch.Size([<span class="number">2</span>, <span class="number">3</span>, <span class="number">100</span>, <span class="number">116</span>]) torch.Size([<span class="number">2</span>, <span class="number">12</span>, <span class="number">100</span>, <span class="number">116</span>])</span><br><span class="line"><span class="number">2</span> torch.Size([<span class="number">2</span>, <span class="number">3</span>, <span class="number">50</span>, <span class="number">58</span>]) torch.Size([<span class="number">2</span>, <span class="number">12</span>, <span class="number">50</span>, <span class="number">58</span>])</span><br><span class="line"><span class="number">3</span> torch.Size([<span class="number">2</span>, <span class="number">3</span>, <span class="number">25</span>, <span class="number">29</span>]) torch.Size([<span class="number">2</span>, <span class="number">12</span>, <span class="number">25</span>, <span class="number">29</span>])</span><br><span class="line"><span class="number">4</span> torch.Size([<span class="number">2</span>, <span class="number">3</span>, <span class="number">13</span>, <span class="number">15</span>]) torch.Size([<span class="number">2</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">15</span>])</span><br><span class="line"></span><br><span class="line">num_anchors = <span class="number">3</span>         <span class="comment"># anchors数量</span></span><br><span class="line">num_point_of_bboxes = num_anchors * <span class="number">4</span> = <span class="number">12</span>  <span class="comment"># 1个anchor有4个坐标值，那么3个anchor就有12个坐标值。</span></span><br></pre></td></tr></table></figure><br>features 是一个含有5个feature map的特征金字塔，经过<code>self.head</code> RPNHead 操作后返回的是5个对应的目标feature map和5个预测bbox偏移量。</p>
<p><strong>定义代码</strong>：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RPNHead</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Adds a simple RPN Head with classification and regression heads</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">        in_channels (int): number of channels of the input feature</span></span><br><span class="line"><span class="string">        num_anchors (int): number of anchors to be predicted</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_channels, num_anchors)</span>:</span></span><br><span class="line">        super(RPNHead, self).__init__()</span><br><span class="line">        self.conv = nn.Conv2d(</span><br><span class="line">            in_channels, in_channels, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line">        self.cls_logits = nn.Conv2d(in_channels, num_anchors, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>)</span><br><span class="line">        self.bbox_pred = nn.Conv2d(</span><br><span class="line">            in_channels, num_anchors * <span class="number">4</span>, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> l <span class="keyword">in</span> self.children():</span><br><span class="line">            torch.nn.init.normal_(l.weight, std=<span class="number">0.01</span>)</span><br><span class="line">            torch.nn.init.constant_(l.bias, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        logits = []</span><br><span class="line">        bbox_reg = []</span><br><span class="line">        <span class="keyword">for</span> feature <span class="keyword">in</span> x:</span><br><span class="line">            t = F.relu(self.conv(feature))</span><br><span class="line">            logits.append(self.cls_logits(t))</span><br><span class="line">            bbox_reg.append(self.bbox_pred(t))</span><br><span class="line">        <span class="keyword">return</span> logits, bbox_reg</span><br></pre></td></tr></table></figure></p>
<p>通过forward可以知道，RPNHead就是将输入的金字塔特征依次做如下的操作：</p>
<pre class="mermaid">graph TD;
    A[conv: 保持输入输出channel不变]-->B[cls_logits: 输出num_anchors个特征图];
    A-->C[bbox_pred: 输出num_anchors*4个特征图];</pre>


<h3 id="生成-anchors"><a href="#生成-anchors" class="headerlink" title="生成 anchors"></a>生成 anchors</h3><p><strong>调用代码</strong>：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">anchors = self.anchor_generator(images, features)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># output:</span></span><br><span class="line"><span class="keyword">for</span> i, anchor <span class="keyword">in</span> enumerate(anchors):</span><br><span class="line">    print(i, anchor.shape)</span><br><span class="line">    </span><br><span class="line"><span class="number">0</span> torch.Size([<span class="number">185460</span>, <span class="number">4</span>])</span><br><span class="line"><span class="number">1</span> torch.Size([<span class="number">185460</span>, <span class="number">4</span>])</span><br></pre></td></tr></table></figure></p>
<p>生成 anchors 的具体方法没有细看，下面先贴出代码:</p>
<p><strong>定义代码</strong>：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AnchorGenerator</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">        self,</span></span></span><br><span class="line"><span class="function"><span class="params">        sizes=<span class="params">(<span class="number">128</span>, <span class="number">256</span>, <span class="number">512</span>)</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">        aspect_ratios=<span class="params">(<span class="number">0.5</span>, <span class="number">1.0</span>, <span class="number">2.0</span>)</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">    )</span>:</span></span><br><span class="line">        super(AnchorGenerator, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> isinstance(sizes[<span class="number">0</span>], (list, tuple)):</span><br><span class="line">            <span class="comment"># TODO change this</span></span><br><span class="line">            sizes = tuple((s,) <span class="keyword">for</span> s <span class="keyword">in</span> sizes)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> isinstance(aspect_ratios[<span class="number">0</span>], (list, tuple)):</span><br><span class="line">            aspect_ratios = (aspect_ratios,) * len(sizes)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> len(sizes) == len(aspect_ratios)</span><br><span class="line"></span><br><span class="line">        self.sizes = sizes</span><br><span class="line">        self.aspect_ratios = aspect_ratios</span><br><span class="line">        self.cell_anchors = <span class="literal">None</span></span><br><span class="line">        self._cache = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, image_list, feature_maps)</span>:</span></span><br><span class="line">        grid_sizes = tuple([feature_map.shape[<span class="number">-2</span>:] <span class="keyword">for</span> feature_map <span class="keyword">in</span> feature_maps])</span><br><span class="line">        image_size = image_list.tensors.shape[<span class="number">-2</span>:]</span><br><span class="line">        strides = tuple((image_size[<span class="number">0</span>] / g[<span class="number">0</span>], image_size[<span class="number">1</span>] / g[<span class="number">1</span>]) <span class="keyword">for</span> g <span class="keyword">in</span> grid_sizes)</span><br><span class="line">        self.set_cell_anchors(feature_maps[<span class="number">0</span>].device)</span><br><span class="line">        anchors_over_all_feature_maps = self.cached_grid_anchors(grid_sizes, strides)</span><br><span class="line">        anchors = []</span><br><span class="line">        <span class="keyword">for</span> i, (image_height, image_width) <span class="keyword">in</span> enumerate(image_list.image_sizes):</span><br><span class="line">            anchors_in_image = []</span><br><span class="line">            <span class="keyword">for</span> anchors_per_feature_map <span class="keyword">in</span> anchors_over_all_feature_maps:</span><br><span class="line">                anchors_in_image.append(anchors_per_feature_map)</span><br><span class="line">            anchors.append(anchors_in_image)</span><br><span class="line">        anchors = [torch.cat(anchors_per_image) <span class="keyword">for</span> anchors_per_image <span class="keyword">in</span> anchors]</span><br><span class="line">        <span class="keyword">return</span> anchors</span><br></pre></td></tr></table></figure></p>
<h3 id="生成-proposal"><a href="#生成-proposal" class="headerlink" title="生成 proposal"></a>生成 proposal</h3><p><strong>调用代码</strong>：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">objectness, pred_bbox_deltas = concat_box_prediction_layers(objectness, pred_bbox_deltas)  <span class="comment"># concat目标feature_map和bbox偏移量</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># output:</span></span><br><span class="line">print(objectness.shape, pred_bbox_deltas.shape)</span><br><span class="line">torch.Size([<span class="number">370920</span>, <span class="number">1</span>]) torch.Size([<span class="number">370920</span>, <span class="number">4</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------------------</span></span><br><span class="line"></span><br><span class="line">proposals = self.box_coder.decode(pred_bbox_deltas.detach(), anchors)  <span class="comment"># 将bbox偏移量转化为图像坐标系中的实际坐标</span></span><br><span class="line">proposals = proposals.view(num_images, <span class="number">-1</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># output:</span></span><br><span class="line">print(proposals.shape)</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">185460</span>, <span class="number">4</span>])</span><br></pre></td></tr></table></figure></p>
<h3 id="过滤-proposal"><a href="#过滤-proposal" class="headerlink" title="过滤 proposal"></a>过滤 proposal</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">boxes, scores = self.filter_proposals(proposals, objectness, images.image_sizes, num_anchors_per_level)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># output:</span></span><br><span class="line"><span class="keyword">for</span> i, (box, sco) <span class="keyword">in</span> enumerate(zip(boxes, scores)):</span><br><span class="line">    print(i, box.shape, sco.shape)    </span><br><span class="line">    </span><br><span class="line"><span class="number">0</span> torch.Size([<span class="number">2000</span>, <span class="number">4</span>]) torch.Size([<span class="number">2000</span>])</span><br><span class="line"><span class="number">1</span> torch.Size([<span class="number">2000</span>, <span class="number">4</span>]) torch.Size([<span class="number">2000</span>])</span><br></pre></td></tr></table></figure>
<h3 id="compute-loss"><a href="#compute-loss" class="headerlink" title="compute loss"></a>compute loss</h3><p>如果是训练阶段则需要计算loss，但如果是测试阶段则 RPN 直接返回上面filter_proposals生成的2000个proposal框即可。</p>
<p><strong>step1</strong>: 在正式计算 loss 之前，首先要生成 ground_truth，这里是根据 anchors 生成匹配的 ground_truth。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> self.training:</span><br><span class="line">    labels, matched_gt_boxes = self.assign_targets_to_anchors(anchors, targets)</span><br><span class="line">    regression_targets = self.box_coder.encode(matched_gt_boxes, anchors)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># output 1:</span></span><br><span class="line"><span class="keyword">for</span> i, (label, gtbox) <span class="keyword">in</span> enumerate(zip(labels, matched_gt_boxes)):</span><br><span class="line">    print(i, label.shape, gtbox.shape)  </span><br><span class="line">    </span><br><span class="line"><span class="number">0</span> torch.Size([<span class="number">185460</span>]) torch.Size([<span class="number">185460</span>, <span class="number">4</span>])</span><br><span class="line"><span class="number">1</span> torch.Size([<span class="number">185460</span>]) torch.Size([<span class="number">185460</span>, <span class="number">4</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># output 2:</span></span><br><span class="line"><span class="keyword">for</span> i, label <span class="keyword">in</span> enumerate(labels):</span><br><span class="line">    print(<span class="string">'&#123;&#125;, number of background bbox: &#123;&#125;'</span>.format(i, (label.numpy() == <span class="number">0</span>).sum()))</span><br><span class="line">    print(<span class="string">'&#123;&#125;, number of background bbox: &#123;&#125;'</span>.format(i, (label.numpy() == <span class="number">1</span>).sum()))            </span><br><span class="line">    </span><br><span class="line"><span class="number">0</span>, number of background bbox: <span class="number">185060</span></span><br><span class="line"><span class="number">0</span>, number of background bbox: <span class="number">12</span></span><br><span class="line"><span class="number">1</span>, number of background bbox: <span class="number">185124</span></span><br><span class="line"><span class="number">1</span>, number of background bbox: <span class="number">4</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># output 3:</span></span><br><span class="line"><span class="keyword">for</span> target <span class="keyword">in</span> regression_targets:</span><br><span class="line">    print(target.shape)</span><br><span class="line">    </span><br><span class="line">torch.Size([<span class="number">185460</span>, <span class="number">4</span>])</span><br><span class="line">torch.Size([<span class="number">185460</span>, <span class="number">4</span>])</span><br></pre></td></tr></table></figure></p>
<p><strong>step2</strong>: 计算loss<br>通过前面的 filter_proposals 后还剩下 2000 个 proposal 框，但是在计算 loss 的时候并不是将这 2000 个框全部都用上的，而是只使用了其中的一部分。</p>
<p>具体的 loss 计算分为两个部分，分别是“bbox 回归 loss”和“目标框分类 loss”，具体流程看下面代码注释吧。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RegionProposalNetwork</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute_loss</span><span class="params">(self, objectness, pred_bbox_deltas, labels, regression_targets)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Arguments:</span></span><br><span class="line"><span class="string">            objectness (Tensor)</span></span><br><span class="line"><span class="string">            pred_bbox_deltas (Tensor)</span></span><br><span class="line"><span class="string">            labels (List[Tensor])</span></span><br><span class="line"><span class="string">            regression_targets (List[Tensor])</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            objectness_loss (Tensor)</span></span><br><span class="line"><span class="string">            box_loss (Tensor</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line"></span><br><span class="line">        <span class="string">"""output:</span></span><br><span class="line"><span class="string">        &gt; print(labels.shape)</span></span><br><span class="line"><span class="string">        &gt; torch.Size([370920])</span></span><br><span class="line"><span class="string">        此时一共有37w多个标签，对应这37w多个目标。</span></span><br><span class="line"><span class="string">        下面开始做正负样本均衡：</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        sampled_pos_inds, sampled_neg_inds = self.fg_bg_sampler(labels)</span><br><span class="line">        sampled_pos_inds = torch.nonzero(torch.cat(sampled_pos_inds, dim=<span class="number">0</span>)).squeeze(<span class="number">1</span>)</span><br><span class="line">        sampled_neg_inds = torch.nonzero(torch.cat(sampled_neg_inds, dim=<span class="number">0</span>)).squeeze(<span class="number">1</span>)</span><br><span class="line">        <span class="string">"""output:</span></span><br><span class="line"><span class="string">        &gt; print(sampled_neg_inds.shape, sampled_pos_inds.shape)</span></span><br><span class="line"><span class="string">        &gt; torch.Size([496]) torch.Size([16])</span></span><br><span class="line"><span class="string">        做完正负样本均衡后，负样本还剩496个，正样本还剩16个</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line"></span><br><span class="line">        sampled_inds = torch.cat([sampled_pos_inds, sampled_neg_inds], dim=<span class="number">0</span>)</span><br><span class="line">        <span class="string">"""output:</span></span><br><span class="line"><span class="string">        &gt; print(sampled_inds.shape)</span></span><br><span class="line"><span class="string">        &gt; torch.Size([512])</span></span><br><span class="line"><span class="string">        将正负样本标签合并到一起。</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line"></span><br><span class="line">        objectness = objectness.flatten()</span><br><span class="line"></span><br><span class="line">        labels = torch.cat(labels, dim=<span class="number">0</span>)</span><br><span class="line">        regression_targets = torch.cat(regression_targets, dim=<span class="number">0</span>)</span><br><span class="line">        <span class="string">"""output:</span></span><br><span class="line"><span class="string">        &gt; print(labels.shape, regression_targets.shape)</span></span><br><span class="line"><span class="string">        &gt; torch.Size([370920]) torch.Size([370920, 4])</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># bbox 回归</span></span><br><span class="line">        box_loss = F.l1_loss(</span><br><span class="line">            pred_bbox_deltas[sampled_pos_inds],  <span class="comment"># 预测的 bbox</span></span><br><span class="line">            regression_targets[sampled_pos_inds],  <span class="comment"># 要回归的目标bbox，即真实bbox</span></span><br><span class="line">            reduction=<span class="string">"sum"</span>,  <span class="comment"># F.l1_loss本身是逐元素计算，但是reduction设置成“sum”后表示返回求和值。</span></span><br><span class="line">        ) / (sampled_inds.numel())  <span class="comment"># 取平均</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算交叉熵</span></span><br><span class="line">        objectness_loss = F.binary_cross_entropy_with_logits(</span><br><span class="line">            objectness[sampled_inds], labels[sampled_inds]</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> objectness_loss, box_loss</span><br></pre></td></tr></table></figure>
<p>l1_loss 计算公式：$l_n = \vert x_n - y_n \vert$</p>
<h2 id="ROI-对齐"><a href="#ROI-对齐" class="headerlink" title="ROI 对齐"></a>ROI 对齐</h2><p>TODO</p>
<h2 id="对检测到的目标框做一些postprocess-后续处理"><a href="#对检测到的目标框做一些postprocess-后续处理" class="headerlink" title="对检测到的目标框做一些postprocess(后续处理)"></a>对检测到的目标框做一些postprocess(后续处理)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GeneralizedRCNNTransform</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">postprocess</span><span class="params">(self, result, image_shapes, original_image_sizes)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.training:</span><br><span class="line">            <span class="keyword">return</span> result</span><br><span class="line">        <span class="keyword">for</span> i, (pred, im_s, o_im_s) <span class="keyword">in</span> enumerate(zip(result, image_shapes, original_image_sizes)):</span><br><span class="line">            boxes = pred[<span class="string">"boxes"</span>]</span><br><span class="line">            boxes = resize_boxes(boxes, im_s, o_im_s)</span><br><span class="line">            result[i][<span class="string">"boxes"</span>] = boxes</span><br><span class="line">            <span class="keyword">if</span> <span class="string">"masks"</span> <span class="keyword">in</span> pred:</span><br><span class="line">                masks = pred[<span class="string">"masks"</span>]</span><br><span class="line">                masks = paste_masks_in_image(masks, boxes, o_im_s)</span><br><span class="line">                result[i][<span class="string">"masks"</span>] = masks</span><br><span class="line">            <span class="keyword">if</span> <span class="string">"keypoints"</span> <span class="keyword">in</span> pred:</span><br><span class="line">                keypoints = pred[<span class="string">"keypoints"</span>]</span><br><span class="line">                keypoints = resize_keypoints(keypoints, im_s, o_im_s)</span><br><span class="line">                result[i][<span class="string">"keypoints"</span>] = keypoints</span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<h2 id="return"><a href="#return" class="headerlink" title="return"></a>return</h2><p>如果是训练阶段，则返回训练 losses 字典<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">losses = &#123;&#125;</span><br><span class="line">losses.update(detector_losses)</span><br><span class="line">losses.update(proposal_losses)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># output:</span></span><br><span class="line">print(losses)</span><br><span class="line">&#123;<span class="string">'loss_box_reg'</span>: tensor(<span class="number">0.1985</span>, grad_fn=&lt;DivBackward0&gt;),</span><br><span class="line"> <span class="string">'loss_classifier'</span>: tensor(<span class="number">1.0829</span>, grad_fn=&lt;NllLossBackward&gt;),</span><br><span class="line"> <span class="string">'loss_objectness'</span>: tensor(<span class="number">0.0291</span>, grad_fn=&lt;BinaryCrossEntropyWithLogitsBackward&gt;),</span><br><span class="line"> <span class="string">'loss_rpn_box_reg'</span>: tensor(<span class="number">0.0046</span>, grad_fn=&lt;DivBackward0&gt;)&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>[1] torchvision.models.detection<br>[2] DeepShare.net &gt; PyTorch框架班</p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/02/28/PyTorch%E7%AC%94%E8%AE%B0/%E3%80%90Entries%E3%80%91C++%20Production-1%20libtorch%20first%20time/" rel="prev" title="PyTorch笔记/【Entries】C++ Production-1 libtorch first time">
      <i class="fa fa-chevron-left"></i> PyTorch笔记/【Entries】C++ Production-1 libtorch first time
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/03/21/PyTorch%E7%AC%94%E8%AE%B0/%E3%80%90Entries%E3%80%91C++%20Production-3%20libtorch%20&%20opencv%20in%20windows/" rel="next" title="PyTorch笔记/【Entries】C++ Production-3 libtorch & opencv in windows">
      PyTorch笔记/【Entries】C++ Production-3 libtorch & opencv in windows <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#数据集以及训练主函数代码"><span class="nav-number">1.</span> <span class="nav-text">数据集以及训练主函数代码</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#模型定义"><span class="nav-number">2.</span> <span class="nav-text">模型定义</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#数据准备"><span class="nav-number">3.</span> <span class="nav-text">数据准备</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#从-Dataset-取样本"><span class="nav-number">3.1.</span> <span class="nav-text">从 Dataset 取样本</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Dataset-每次会返回一个-tuple："><span class="nav-number">3.2.</span> <span class="nav-text">Dataset 每次会返回一个 tuple：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DataLoader-将这些-tuple-组成一个-list"><span class="nav-number">3.3.</span> <span class="nav-text">DataLoader 将这些 tuple 组成一个 list</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DataLoader-调用用户自定义的-collate-fn-将这个-list-重组成如下形式："><span class="nav-number">3.4.</span> <span class="nav-text">DataLoader 调用用户自定义的 collate_fn 将这个 list 重组成如下形式：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#现在可以将这些数据搬运到-GPU-上了"><span class="nav-number">3.5.</span> <span class="nav-text">现在可以将这些数据搬运到 GPU 上了</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#开始网络前向计算"><span class="nav-number">4.</span> <span class="nav-text">开始网络前向计算</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#对images和targets做transform操作"><span class="nav-number">4.1.</span> <span class="nav-text">对images和targets做transform操作</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#在for循环中对每张image和其对应的target做normalize和resize操作"><span class="nav-number">4.1.1.</span> <span class="nav-text">在for循环中对每张image和其对应的target做normalize和resize操作</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#依次对images中的每张image做normalize操作"><span class="nav-number">4.1.1.1.</span> <span class="nav-text">依次对images中的每张image做normalize操作</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#依次对images和targets做resize操作"><span class="nav-number">4.1.1.2.</span> <span class="nav-text">依次对images和targets做resize操作</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#将每张图片-tensor-缩放到一个随机选中的尺度"><span class="nav-number">4.1.1.2.1.</span> <span class="nav-text">将每张图片(tensor)缩放到一个随机选中的尺度</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#将图片对应的-ground-turth-也要缩放到这个尺度"><span class="nav-number">4.1.1.2.2.</span> <span class="nav-text">将图片对应的 ground_turth 也要缩放到这个尺度</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#如果有masks或者keypoints，也要做相应的缩放"><span class="nav-number">4.1.1.2.3.</span> <span class="nav-text">如果有masks或者keypoints，也要做相应的缩放</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#提取images中每个tensor的尺寸并存入一个局部变量-image-sizes-中"><span class="nav-number">4.1.2.</span> <span class="nav-text">提取images中每个tensor的尺寸并存入一个局部变量 image_sizes 中</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#将list形式的images重组为一个4维tensor"><span class="nav-number">4.1.3.</span> <span class="nav-text">将list形式的images重组为一个4维tensor</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#将此时的images-此时已是4维tensor-和image-sizes都用-ImageList-封装一下"><span class="nav-number">4.1.4.</span> <span class="nav-text">将此时的images(此时已是4维tensor)和image_sizes都用 ImageList 封装一下</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#transform-forward-返回-image-list-和-targets"><span class="nav-number">4.1.5.</span> <span class="nav-text">transform forward 返回 image_list 和 targets</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#transform-总结"><span class="nav-number">4.1.6.</span> <span class="nav-text">transform 总结</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#backbone"><span class="nav-number">4.2.</span> <span class="nav-text">backbone</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#rpn"><span class="nav-number">4.3.</span> <span class="nav-text">rpn</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#执行-RPNHead-操作"><span class="nav-number">4.3.1.</span> <span class="nav-text">执行 RPNHead 操作</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#生成-anchors"><span class="nav-number">4.3.2.</span> <span class="nav-text">生成 anchors</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#生成-proposal"><span class="nav-number">4.3.3.</span> <span class="nav-text">生成 proposal</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#过滤-proposal"><span class="nav-number">4.3.4.</span> <span class="nav-text">过滤 proposal</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#compute-loss"><span class="nav-number">4.3.5.</span> <span class="nav-text">compute loss</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ROI-对齐"><span class="nav-number">4.4.</span> <span class="nav-text">ROI 对齐</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#对检测到的目标框做一些postprocess-后续处理"><span class="nav-number">4.5.</span> <span class="nav-text">对检测到的目标框做一些postprocess(后续处理)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#return"><span class="nav-number">4.6.</span> <span class="nav-text">return</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#参考文献"><span class="nav-number">5.</span> <span class="nav-text">参考文献</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name"></p>
  <div class="site-description" itemprop="description">其实，我是一个搬运工！</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">124</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder"></span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.7.0
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  













<script>
if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js', () => {
    mermaid.initialize({
      theme: 'default',
      logLevel: 3,
      flowchart: { curve: 'linear' },
      gantt: { axisFormat: '%m/%d/%Y' },
      sequence: { actorMargin: 50 }
    });
  }, window.mermaid);
}
</script>


  

  
      
<script type="text/x-mathjax-config">
    MathJax.Ajax.config.path['mhchem'] = '//cdn.jsdelivr.net/npm/mathjax-mhchem@3';

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        extensions: ['[mhchem]/mhchem.js'],
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    

  

</body>
</html>
